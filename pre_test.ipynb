{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35738532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def make_layer(config=[64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 'M', 'B', 'M']):\n",
    "    layers = []\n",
    "    in_channel = 1\n",
    "    for out_channel in config:\n",
    "        if out_channel == \"M\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        elif out_channel == 'B':\n",
    "            layers.append(nn.Conv2d(in_channel, in_channel, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(in_channel))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channel = out_channel\n",
    "    \n",
    "    #layers.append(nn.AdaptiveAvgPool2d((2, 2)))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class NET(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=2350):\n",
    "        super(NET, self).__init__()\n",
    "        self.features = make_layer()\n",
    "        \n",
    "        # ImageNet\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = torch.flatten(out,1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bb64f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([672, 1, 64, 64])\n",
      "Shape of y: torch.Size([672]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((64, 64)), # (h, w) 순서\n",
    "            #transforms.ToPILImage(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "train = ImageFolder(root=\"./_data/syllable/\", transform=transform, target_transform=None)\n",
    "test = ImageFolder(root=\"./_data/syllable_test/\", transform=transform, target_transform=None)\n",
    "\n",
    "batch_size = int(len(train)/500)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "for X, y in train_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd6cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]             640\n",
      "              ReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3           [-1, 64, 64, 64]          36,928\n",
      "              ReLU-4           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-5           [-1, 64, 32, 32]               0\n",
      "            Conv2d-6          [-1, 128, 32, 32]          73,856\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]         147,584\n",
      "              ReLU-9          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 256, 16, 16]         295,168\n",
      "             ReLU-12          [-1, 256, 16, 16]               0\n",
      "           Conv2d-13          [-1, 256, 16, 16]         590,080\n",
      "             ReLU-14          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16            [-1, 512, 8, 8]       1,180,160\n",
      "             ReLU-17            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-18            [-1, 512, 4, 4]               0\n",
      "           Conv2d-19            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-20            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-21            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-22            [-1, 512, 2, 2]               0\n",
      "           Linear-23                 [-1, 2350]       4,815,150\n",
      "================================================================\n",
      "Total params: 9,499,886\n",
      "Trainable params: 9,499,886\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 15.66\n",
      "Params size (MB): 36.24\n",
      "Estimated Total Size (MB): 51.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NET().to(device)\n",
    "total_epoch = 10\n",
    "torchsummary.summary(model, (1, 64, 64), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c6920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NET().to(device)\n",
    "#model.load_state_dict(torch.load('./model_5.pth'))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], iteration [1/501] Loss: 7.8653\n",
      "Epoch [1/10], iteration [2/501] Loss: 34.9906\n",
      "Epoch [1/10], iteration [3/501] Loss: 52.7796\n",
      "Epoch [1/10], iteration [4/501] Loss: 51.1427\n",
      "Epoch [1/10], iteration [5/501] Loss: 50.4409\n",
      "Epoch [1/10], iteration [6/501] Loss: 47.9556\n",
      "Epoch [1/10], iteration [7/501] Loss: 47.1412\n",
      "Epoch [1/10], iteration [8/501] Loss: 46.6265\n",
      "Epoch [1/10], iteration [9/501] Loss: 45.1092\n",
      "Epoch [1/10], iteration [10/501] Loss: 42.3813\n",
      "Epoch [1/10], iteration [11/501] Loss: 40.3010\n",
      "Epoch [1/10], iteration [12/501] Loss: 37.4843\n",
      "Epoch [1/10], iteration [13/501] Loss: 35.3916\n",
      "Epoch [1/10], iteration [14/501] Loss: 31.9658\n",
      "Epoch [1/10], iteration [15/501] Loss: 29.4778\n",
      "Epoch [1/10], iteration [16/501] Loss: 27.5530\n",
      "Epoch [1/10], iteration [17/501] Loss: 26.2237\n",
      "Epoch [1/10], iteration [18/501] Loss: 24.1562\n",
      "Epoch [1/10], iteration [19/501] Loss: 21.8740\n",
      "Epoch [1/10], iteration [20/501] Loss: 20.9914\n",
      "Epoch [1/10], iteration [21/501] Loss: 19.5983\n",
      "Epoch [1/10], iteration [22/501] Loss: 17.9812\n",
      "Epoch [1/10], iteration [23/501] Loss: 17.6368\n",
      "Epoch [1/10], iteration [24/501] Loss: 16.3748\n",
      "Epoch [1/10], iteration [25/501] Loss: 15.1105\n",
      "Epoch [1/10], iteration [26/501] Loss: 14.3711\n",
      "Epoch [1/10], iteration [27/501] Loss: 13.1027\n",
      "Epoch [1/10], iteration [28/501] Loss: 13.1026\n",
      "Epoch [1/10], iteration [29/501] Loss: 12.7298\n",
      "Epoch [1/10], iteration [30/501] Loss: 11.7858\n",
      "Epoch [1/10], iteration [31/501] Loss: 11.6671\n",
      "Epoch [1/10], iteration [32/501] Loss: 11.4167\n",
      "Epoch [1/10], iteration [33/501] Loss: 10.9443\n",
      "Epoch [1/10], iteration [34/501] Loss: 10.6002\n",
      "Epoch [1/10], iteration [35/501] Loss: 10.6747\n",
      "Epoch [1/10], iteration [36/501] Loss: 10.0564\n",
      "Epoch [1/10], iteration [37/501] Loss: 10.0823\n",
      "Epoch [1/10], iteration [38/501] Loss: 9.6544\n",
      "Epoch [1/10], iteration [39/501] Loss: 9.6534\n",
      "Epoch [1/10], iteration [40/501] Loss: 9.4034\n",
      "Epoch [1/10], iteration [41/501] Loss: 8.8737\n",
      "Epoch [1/10], iteration [42/501] Loss: 8.9041\n",
      "Epoch [1/10], iteration [43/501] Loss: 8.7415\n",
      "Epoch [1/10], iteration [44/501] Loss: 8.7273\n",
      "Epoch [1/10], iteration [45/501] Loss: 8.4175\n",
      "Epoch [1/10], iteration [46/501] Loss: 8.2970\n",
      "Epoch [1/10], iteration [47/501] Loss: 8.1953\n",
      "Epoch [1/10], iteration [48/501] Loss: 8.2408\n",
      "Epoch [1/10], iteration [49/501] Loss: 8.1347\n",
      "Epoch [1/10], iteration [50/501] Loss: 7.9794\n",
      "Epoch [1/10], iteration [51/501] Loss: 7.9614\n",
      "Epoch [1/10], iteration [52/501] Loss: 7.9582\n",
      "Epoch [1/10], iteration [53/501] Loss: 7.8940\n",
      "Epoch [1/10], iteration [54/501] Loss: 7.8462\n",
      "Epoch [1/10], iteration [55/501] Loss: 7.8479\n",
      "Epoch [1/10], iteration [56/501] Loss: 7.8299\n",
      "Epoch [1/10], iteration [57/501] Loss: 7.8282\n",
      "Epoch [1/10], iteration [58/501] Loss: 7.7946\n",
      "Epoch [1/10], iteration [59/501] Loss: 7.8020\n",
      "Epoch [1/10], iteration [60/501] Loss: 7.7978\n",
      "Epoch [1/10], iteration [61/501] Loss: 7.7947\n",
      "Epoch [1/10], iteration [62/501] Loss: 7.7900\n",
      "Epoch [1/10], iteration [63/501] Loss: 7.7935\n",
      "Epoch [1/10], iteration [64/501] Loss: 7.7798\n",
      "Epoch [1/10], iteration [65/501] Loss: 7.7789\n",
      "Epoch [1/10], iteration [66/501] Loss: 7.7692\n",
      "Epoch [1/10], iteration [67/501] Loss: 7.7693\n",
      "Epoch [1/10], iteration [68/501] Loss: 7.7766\n",
      "Epoch [1/10], iteration [69/501] Loss: 7.7724\n",
      "Epoch [1/10], iteration [70/501] Loss: 7.7752\n",
      "Epoch [1/10], iteration [71/501] Loss: 7.7615\n",
      "Epoch [1/10], iteration [72/501] Loss: 7.7737\n",
      "Epoch [1/10], iteration [73/501] Loss: 7.7765\n",
      "Epoch [1/10], iteration [74/501] Loss: 7.7696\n",
      "Epoch [1/10], iteration [75/501] Loss: 7.7693\n",
      "Epoch [1/10], iteration [76/501] Loss: 7.7694\n",
      "Epoch [1/10], iteration [77/501] Loss: 7.7613\n",
      "Epoch [1/10], iteration [78/501] Loss: 7.7653\n",
      "Epoch [1/10], iteration [79/501] Loss: 7.7888\n",
      "Epoch [1/10], iteration [80/501] Loss: 7.7655\n",
      "Epoch [1/10], iteration [81/501] Loss: 7.7667\n",
      "Epoch [1/10], iteration [82/501] Loss: 7.7685\n",
      "Epoch [1/10], iteration [83/501] Loss: 7.7680\n",
      "Epoch [1/10], iteration [84/501] Loss: 7.7644\n",
      "Epoch [1/10], iteration [85/501] Loss: 7.7761\n",
      "Epoch [1/10], iteration [86/501] Loss: 7.7690\n",
      "Epoch [1/10], iteration [87/501] Loss: 7.7709\n",
      "Epoch [1/10], iteration [88/501] Loss: 7.7652\n",
      "Epoch [1/10], iteration [89/501] Loss: 7.7669\n",
      "Epoch [1/10], iteration [90/501] Loss: 7.7645\n",
      "Epoch [1/10], iteration [91/501] Loss: 7.7586\n",
      "Epoch [1/10], iteration [92/501] Loss: 7.7651\n",
      "Epoch [1/10], iteration [93/501] Loss: 7.7637\n",
      "Epoch [1/10], iteration [94/501] Loss: 7.7648\n",
      "Epoch [1/10], iteration [95/501] Loss: 7.7700\n",
      "Epoch [1/10], iteration [96/501] Loss: 7.7532\n",
      "Epoch [1/10], iteration [97/501] Loss: 7.7633\n",
      "Epoch [1/10], iteration [98/501] Loss: 7.7715\n",
      "Epoch [1/10], iteration [99/501] Loss: 7.7597\n",
      "Epoch [1/10], iteration [100/501] Loss: 7.7625\n",
      "Epoch [1/10], iteration [101/501] Loss: 7.7636\n",
      "Epoch [1/10], iteration [102/501] Loss: 7.7597\n",
      "Epoch [1/10], iteration [103/501] Loss: 7.7578\n",
      "Epoch [1/10], iteration [104/501] Loss: 7.7563\n",
      "Epoch [1/10], iteration [105/501] Loss: 7.7525\n",
      "Epoch [1/10], iteration [106/501] Loss: 7.7528\n",
      "Epoch [1/10], iteration [107/501] Loss: 7.7496\n",
      "Epoch [1/10], iteration [108/501] Loss: 7.7563\n",
      "Epoch [1/10], iteration [109/501] Loss: 7.7499\n",
      "Epoch [1/10], iteration [110/501] Loss: 7.7345\n",
      "Epoch [1/10], iteration [111/501] Loss: 7.7398\n",
      "Epoch [1/10], iteration [112/501] Loss: 7.7286\n",
      "Epoch [1/10], iteration [113/501] Loss: 7.7226\n",
      "Epoch [1/10], iteration [114/501] Loss: 7.7180\n",
      "Epoch [1/10], iteration [115/501] Loss: 7.7139\n",
      "Epoch [1/10], iteration [116/501] Loss: 7.7294\n",
      "Epoch [1/10], iteration [117/501] Loss: 7.7377\n",
      "Epoch [1/10], iteration [118/501] Loss: 7.7170\n",
      "Epoch [1/10], iteration [119/501] Loss: 7.7065\n",
      "Epoch [1/10], iteration [120/501] Loss: 7.7071\n",
      "Epoch [1/10], iteration [121/501] Loss: 7.7004\n",
      "Epoch [1/10], iteration [122/501] Loss: 7.7346\n",
      "Epoch [1/10], iteration [123/501] Loss: 7.7138\n",
      "Epoch [1/10], iteration [124/501] Loss: 7.7119\n",
      "Epoch [1/10], iteration [125/501] Loss: 7.7133\n",
      "Epoch [1/10], iteration [126/501] Loss: 7.6737\n",
      "Epoch [1/10], iteration [127/501] Loss: 7.7021\n",
      "Epoch [1/10], iteration [128/501] Loss: 7.6653\n",
      "Epoch [1/10], iteration [129/501] Loss: 7.6529\n",
      "Epoch [1/10], iteration [130/501] Loss: 7.6724\n",
      "Epoch [1/10], iteration [131/501] Loss: 7.6729\n",
      "Epoch [1/10], iteration [132/501] Loss: 7.6782\n",
      "Epoch [1/10], iteration [133/501] Loss: 7.6289\n",
      "Epoch [1/10], iteration [134/501] Loss: 7.6538\n",
      "Epoch [1/10], iteration [135/501] Loss: 7.6514\n",
      "Epoch [1/10], iteration [136/501] Loss: 7.6103\n",
      "Epoch [1/10], iteration [137/501] Loss: 7.6394\n",
      "Epoch [1/10], iteration [138/501] Loss: 7.5770\n",
      "Epoch [1/10], iteration [139/501] Loss: 7.6300\n",
      "Epoch [1/10], iteration [140/501] Loss: 7.6167\n",
      "Epoch [1/10], iteration [141/501] Loss: 7.6159\n",
      "Epoch [1/10], iteration [142/501] Loss: 7.6291\n",
      "Epoch [1/10], iteration [143/501] Loss: 7.5788\n",
      "Epoch [1/10], iteration [144/501] Loss: 7.5911\n",
      "Epoch [1/10], iteration [145/501] Loss: 7.5529\n",
      "Epoch [1/10], iteration [146/501] Loss: 7.5538\n",
      "Epoch [1/10], iteration [147/501] Loss: 7.5325\n",
      "Epoch [1/10], iteration [148/501] Loss: 7.5563\n",
      "Epoch [1/10], iteration [149/501] Loss: 7.5643\n",
      "Epoch [1/10], iteration [150/501] Loss: 7.5289\n",
      "Epoch [1/10], iteration [151/501] Loss: 7.5251\n",
      "Epoch [1/10], iteration [152/501] Loss: 7.5444\n",
      "Epoch [1/10], iteration [153/501] Loss: 7.5152\n",
      "Epoch [1/10], iteration [154/501] Loss: 7.5651\n",
      "Epoch [1/10], iteration [155/501] Loss: 7.5052\n",
      "Epoch [1/10], iteration [156/501] Loss: 7.4876\n",
      "Epoch [1/10], iteration [157/501] Loss: 7.4269\n",
      "Epoch [1/10], iteration [158/501] Loss: 7.4830\n",
      "Epoch [1/10], iteration [159/501] Loss: 7.4758\n",
      "Epoch [1/10], iteration [160/501] Loss: 7.4704\n",
      "Epoch [1/10], iteration [161/501] Loss: 7.4133\n",
      "Epoch [1/10], iteration [162/501] Loss: 7.4210\n",
      "Epoch [1/10], iteration [163/501] Loss: 7.4708\n",
      "Epoch [1/10], iteration [164/501] Loss: 7.4056\n",
      "Epoch [1/10], iteration [165/501] Loss: 7.4416\n",
      "Epoch [1/10], iteration [166/501] Loss: 7.4052\n",
      "Epoch [1/10], iteration [167/501] Loss: 7.3685\n",
      "Epoch [1/10], iteration [168/501] Loss: 7.3530\n",
      "Epoch [1/10], iteration [169/501] Loss: 7.3907\n",
      "Epoch [1/10], iteration [170/501] Loss: 7.3264\n",
      "Epoch [1/10], iteration [171/501] Loss: 7.3936\n",
      "Epoch [1/10], iteration [172/501] Loss: 7.3452\n",
      "Epoch [1/10], iteration [173/501] Loss: 7.3003\n",
      "Epoch [1/10], iteration [174/501] Loss: 7.3324\n",
      "Epoch [1/10], iteration [175/501] Loss: 7.3177\n",
      "Epoch [1/10], iteration [176/501] Loss: 7.2996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], iteration [177/501] Loss: 7.2353\n",
      "Epoch [1/10], iteration [178/501] Loss: 7.2632\n",
      "Epoch [1/10], iteration [179/501] Loss: 7.2854\n",
      "Epoch [1/10], iteration [180/501] Loss: 7.1083\n",
      "Epoch [1/10], iteration [181/501] Loss: 7.2463\n",
      "Epoch [1/10], iteration [182/501] Loss: 7.1578\n",
      "Epoch [1/10], iteration [183/501] Loss: 7.2414\n",
      "Epoch [1/10], iteration [184/501] Loss: 7.2470\n",
      "Epoch [1/10], iteration [185/501] Loss: 7.1710\n",
      "Epoch [1/10], iteration [186/501] Loss: 7.1698\n",
      "Epoch [1/10], iteration [187/501] Loss: 7.1697\n",
      "Epoch [1/10], iteration [188/501] Loss: 7.1680\n",
      "Epoch [1/10], iteration [189/501] Loss: 7.1455\n",
      "Epoch [1/10], iteration [190/501] Loss: 7.1589\n",
      "Epoch [1/10], iteration [191/501] Loss: 7.0815\n",
      "Epoch [1/10], iteration [192/501] Loss: 7.1554\n",
      "Epoch [1/10], iteration [193/501] Loss: 7.0172\n",
      "Epoch [1/10], iteration [194/501] Loss: 7.0171\n",
      "Epoch [1/10], iteration [195/501] Loss: 6.9331\n",
      "Epoch [1/10], iteration [196/501] Loss: 6.9752\n",
      "Epoch [1/10], iteration [197/501] Loss: 7.0257\n",
      "Epoch [1/10], iteration [198/501] Loss: 6.9669\n",
      "Epoch [1/10], iteration [199/501] Loss: 6.9376\n",
      "Epoch [1/10], iteration [200/501] Loss: 7.0422\n",
      "Epoch [1/10], iteration [201/501] Loss: 6.9430\n",
      "Epoch [1/10], iteration [202/501] Loss: 6.8341\n",
      "Epoch [1/10], iteration [203/501] Loss: 6.9187\n",
      "Epoch [1/10], iteration [204/501] Loss: 6.8187\n",
      "Epoch [1/10], iteration [205/501] Loss: 6.8730\n",
      "Epoch [1/10], iteration [206/501] Loss: 6.7612\n",
      "Epoch [1/10], iteration [207/501] Loss: 6.7555\n",
      "Epoch [1/10], iteration [208/501] Loss: 6.7649\n",
      "Epoch [1/10], iteration [209/501] Loss: 6.6961\n",
      "Epoch [1/10], iteration [210/501] Loss: 6.7088\n",
      "Epoch [1/10], iteration [211/501] Loss: 6.7747\n",
      "Epoch [1/10], iteration [212/501] Loss: 6.6577\n",
      "Epoch [1/10], iteration [213/501] Loss: 6.6070\n",
      "Epoch [1/10], iteration [214/501] Loss: 6.6883\n",
      "Epoch [1/10], iteration [215/501] Loss: 6.6038\n",
      "Epoch [1/10], iteration [216/501] Loss: 6.5224\n",
      "Epoch [1/10], iteration [217/501] Loss: 6.4986\n",
      "Epoch [1/10], iteration [218/501] Loss: 6.3968\n",
      "Epoch [1/10], iteration [219/501] Loss: 6.4368\n",
      "Epoch [1/10], iteration [220/501] Loss: 6.5138\n",
      "Epoch [1/10], iteration [221/501] Loss: 6.4314\n",
      "Epoch [1/10], iteration [222/501] Loss: 6.3722\n",
      "Epoch [1/10], iteration [223/501] Loss: 6.3389\n",
      "Epoch [1/10], iteration [224/501] Loss: 6.3413\n",
      "Epoch [1/10], iteration [225/501] Loss: 6.2679\n",
      "Epoch [1/10], iteration [226/501] Loss: 6.2941\n",
      "Epoch [1/10], iteration [227/501] Loss: 6.1983\n",
      "Epoch [1/10], iteration [228/501] Loss: 6.2651\n",
      "Epoch [1/10], iteration [229/501] Loss: 6.2377\n",
      "Epoch [1/10], iteration [230/501] Loss: 6.2916\n",
      "Epoch [1/10], iteration [231/501] Loss: 6.1011\n",
      "Epoch [1/10], iteration [232/501] Loss: 6.1238\n",
      "Epoch [1/10], iteration [233/501] Loss: 6.1656\n",
      "Epoch [1/10], iteration [234/501] Loss: 6.0602\n",
      "Epoch [1/10], iteration [235/501] Loss: 6.1609\n",
      "Epoch [1/10], iteration [236/501] Loss: 6.0518\n",
      "Epoch [1/10], iteration [237/501] Loss: 6.0780\n",
      "Epoch [1/10], iteration [238/501] Loss: 6.0315\n",
      "Epoch [1/10], iteration [239/501] Loss: 6.0564\n",
      "Epoch [1/10], iteration [240/501] Loss: 5.9214\n",
      "Epoch [1/10], iteration [241/501] Loss: 6.0541\n",
      "Epoch [1/10], iteration [242/501] Loss: 6.0696\n",
      "Epoch [1/10], iteration [243/501] Loss: 5.9210\n",
      "Epoch [1/10], iteration [244/501] Loss: 5.9372\n",
      "Epoch [1/10], iteration [245/501] Loss: 6.0309\n",
      "Epoch [1/10], iteration [246/501] Loss: 5.8931\n",
      "Epoch [1/10], iteration [247/501] Loss: 5.8117\n",
      "Epoch [1/10], iteration [248/501] Loss: 5.8638\n",
      "Epoch [1/10], iteration [249/501] Loss: 5.8668\n",
      "Epoch [1/10], iteration [250/501] Loss: 5.7375\n",
      "Epoch [1/10], iteration [251/501] Loss: 5.7620\n",
      "Epoch [1/10], iteration [252/501] Loss: 5.5913\n",
      "Epoch [1/10], iteration [253/501] Loss: 5.7096\n",
      "Epoch [1/10], iteration [254/501] Loss: 5.7674\n",
      "Epoch [1/10], iteration [255/501] Loss: 5.7084\n",
      "Epoch [1/10], iteration [256/501] Loss: 5.6368\n",
      "Epoch [1/10], iteration [257/501] Loss: 5.5449\n",
      "Epoch [1/10], iteration [258/501] Loss: 5.7139\n",
      "Epoch [1/10], iteration [259/501] Loss: 5.4808\n",
      "Epoch [1/10], iteration [260/501] Loss: 5.5875\n",
      "Epoch [1/10], iteration [261/501] Loss: 5.6188\n",
      "Epoch [1/10], iteration [262/501] Loss: 5.4467\n",
      "Epoch [1/10], iteration [263/501] Loss: 5.3604\n",
      "Epoch [1/10], iteration [264/501] Loss: 5.4587\n",
      "Epoch [1/10], iteration [265/501] Loss: 5.4319\n",
      "Epoch [1/10], iteration [266/501] Loss: 5.4744\n",
      "Epoch [1/10], iteration [267/501] Loss: 5.3314\n",
      "Epoch [1/10], iteration [268/501] Loss: 5.2052\n",
      "Epoch [1/10], iteration [269/501] Loss: 5.3541\n",
      "Epoch [1/10], iteration [270/501] Loss: 5.2425\n",
      "Epoch [1/10], iteration [271/501] Loss: 5.2549\n",
      "Epoch [1/10], iteration [272/501] Loss: 5.1414\n",
      "Epoch [1/10], iteration [273/501] Loss: 5.1958\n",
      "Epoch [1/10], iteration [274/501] Loss: 5.1949\n",
      "Epoch [1/10], iteration [275/501] Loss: 5.2165\n",
      "Epoch [1/10], iteration [276/501] Loss: 5.0403\n",
      "Epoch [1/10], iteration [277/501] Loss: 5.2177\n",
      "Epoch [1/10], iteration [278/501] Loss: 5.1148\n",
      "Epoch [1/10], iteration [279/501] Loss: 5.0194\n",
      "Epoch [1/10], iteration [280/501] Loss: 5.0805\n",
      "Epoch [1/10], iteration [281/501] Loss: 4.9196\n",
      "Epoch [1/10], iteration [282/501] Loss: 5.0405\n",
      "Epoch [1/10], iteration [283/501] Loss: 4.8615\n",
      "Epoch [1/10], iteration [284/501] Loss: 4.8521\n",
      "Epoch [1/10], iteration [285/501] Loss: 4.8423\n",
      "Epoch [1/10], iteration [286/501] Loss: 4.7820\n",
      "Epoch [1/10], iteration [287/501] Loss: 4.9268\n",
      "Epoch [1/10], iteration [288/501] Loss: 4.7715\n",
      "Epoch [1/10], iteration [289/501] Loss: 4.7958\n",
      "Epoch [1/10], iteration [290/501] Loss: 4.9021\n",
      "Epoch [1/10], iteration [291/501] Loss: 4.7968\n",
      "Epoch [1/10], iteration [292/501] Loss: 4.6690\n",
      "Epoch [1/10], iteration [293/501] Loss: 4.7738\n",
      "Epoch [1/10], iteration [294/501] Loss: 4.7341\n",
      "Epoch [1/10], iteration [295/501] Loss: 4.7970\n",
      "Epoch [1/10], iteration [296/501] Loss: 4.5772\n",
      "Epoch [1/10], iteration [297/501] Loss: 4.7836\n",
      "Epoch [1/10], iteration [298/501] Loss: 4.4661\n",
      "Epoch [1/10], iteration [299/501] Loss: 4.7179\n",
      "Epoch [1/10], iteration [300/501] Loss: 4.4582\n",
      "Epoch [1/10], iteration [301/501] Loss: 4.3704\n",
      "Epoch [1/10], iteration [302/501] Loss: 4.4505\n",
      "Epoch [1/10], iteration [303/501] Loss: 4.3148\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_iteration_per_epoch = int(np.ceil(len(train)/batch_size))\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    model.train()\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch [{}/{}], iteration [{}/{}] Loss: {:.4f}'.format(epoch, total_epoch, iteration+1, total_iteration_per_epoch, loss.item()))\n",
    "    torch.save(model.state_dict(), 'model_' + str(epoch) + \".pth\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for input, target in test_loader:\n",
    "            images = input.to(device)\n",
    "            labels = target.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Epoch [{}/{}], Test Accuracy of the model on the {} test images: {} %'.format(epoch, total_epoch, total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37463e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5214e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2b128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
