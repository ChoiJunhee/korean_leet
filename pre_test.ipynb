{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35738532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def make_layer(config=[64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 'M', 'B', 'M']):\n",
    "    layers = []\n",
    "    in_channel = 1\n",
    "    for out_channel in config:\n",
    "        if out_channel == \"M\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        elif out_channel == 'B':\n",
    "            layers.append(nn.Conv2d(in_channel, in_channel, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(in_channel))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channel = out_channel\n",
    "    \n",
    "    #layers.append(nn.AdaptiveAvgPool2d((2, 2)))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class NET(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=2350):\n",
    "        super(NET, self).__init__()\n",
    "        self.features = make_layer()\n",
    "        \n",
    "        # ImageNet\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = torch.flatten(out,1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bb64f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([672, 1, 64, 64])\n",
      "Shape of y: torch.Size([672]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((64, 64)), # (h, w) 순서\n",
    "            #transforms.ToPILImage(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "train = ImageFolder(root=\"./_data/syllable/\", transform=transform, target_transform=None)\n",
    "test = ImageFolder(root=\"./_data/syllable_test/\", transform=transform, target_transform=None)\n",
    "\n",
    "batch_size = int(len(train)/500)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "for X, y in train_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd6cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]             640\n",
      "              ReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3           [-1, 64, 64, 64]          36,928\n",
      "              ReLU-4           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-5           [-1, 64, 32, 32]               0\n",
      "            Conv2d-6          [-1, 128, 32, 32]          73,856\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 128, 32, 32]         147,584\n",
      "              ReLU-9          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 256, 16, 16]         295,168\n",
      "             ReLU-12          [-1, 256, 16, 16]               0\n",
      "           Conv2d-13          [-1, 256, 16, 16]         590,080\n",
      "             ReLU-14          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16            [-1, 512, 8, 8]       1,180,160\n",
      "             ReLU-17            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-18            [-1, 512, 4, 4]               0\n",
      "           Conv2d-19            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-20            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-21            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-22            [-1, 512, 2, 2]               0\n",
      "           Linear-23                 [-1, 2350]       4,815,150\n",
      "================================================================\n",
      "Total params: 9,499,886\n",
      "Trainable params: 9,499,886\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 15.66\n",
      "Params size (MB): 36.24\n",
      "Estimated Total Size (MB): 51.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NET().to(device)\n",
    "total_epoch = 10\n",
    "torchsummary.summary(model, (1, 64, 64), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c6920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NET().to(device)\n",
    "#model.load_state_dict(torch.load('./model_5.pth'))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4214e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], iteration [1/501] Loss: 7.8653\n",
      "Epoch [1/10], iteration [2/501] Loss: 34.9906\n",
      "Epoch [1/10], iteration [3/501] Loss: 52.7796\n",
      "Epoch [1/10], iteration [4/501] Loss: 51.1427\n",
      "Epoch [1/10], iteration [5/501] Loss: 50.4409\n",
      "Epoch [1/10], iteration [6/501] Loss: 47.9556\n",
      "Epoch [1/10], iteration [7/501] Loss: 47.1412\n",
      "Epoch [1/10], iteration [8/501] Loss: 46.6265\n",
      "Epoch [1/10], iteration [9/501] Loss: 45.1092\n",
      "Epoch [1/10], iteration [10/501] Loss: 42.3813\n",
      "Epoch [1/10], iteration [11/501] Loss: 40.3010\n",
      "Epoch [1/10], iteration [12/501] Loss: 37.4843\n",
      "Epoch [1/10], iteration [13/501] Loss: 35.3916\n",
      "Epoch [1/10], iteration [14/501] Loss: 31.9658\n",
      "Epoch [1/10], iteration [15/501] Loss: 29.4778\n",
      "Epoch [1/10], iteration [16/501] Loss: 27.5530\n",
      "Epoch [1/10], iteration [17/501] Loss: 26.2237\n",
      "Epoch [1/10], iteration [18/501] Loss: 24.1562\n",
      "Epoch [1/10], iteration [19/501] Loss: 21.8740\n",
      "Epoch [1/10], iteration [20/501] Loss: 20.9914\n",
      "Epoch [1/10], iteration [21/501] Loss: 19.5983\n",
      "Epoch [1/10], iteration [22/501] Loss: 17.9812\n",
      "Epoch [1/10], iteration [23/501] Loss: 17.6368\n",
      "Epoch [1/10], iteration [24/501] Loss: 16.3748\n",
      "Epoch [1/10], iteration [25/501] Loss: 15.1105\n",
      "Epoch [1/10], iteration [26/501] Loss: 14.3711\n",
      "Epoch [1/10], iteration [27/501] Loss: 13.1027\n",
      "Epoch [1/10], iteration [28/501] Loss: 13.1026\n",
      "Epoch [1/10], iteration [29/501] Loss: 12.7298\n",
      "Epoch [1/10], iteration [30/501] Loss: 11.7858\n",
      "Epoch [1/10], iteration [31/501] Loss: 11.6671\n",
      "Epoch [1/10], iteration [32/501] Loss: 11.4167\n",
      "Epoch [1/10], iteration [33/501] Loss: 10.9443\n",
      "Epoch [1/10], iteration [34/501] Loss: 10.6002\n",
      "Epoch [1/10], iteration [35/501] Loss: 10.6747\n",
      "Epoch [1/10], iteration [36/501] Loss: 10.0564\n",
      "Epoch [1/10], iteration [37/501] Loss: 10.0823\n",
      "Epoch [1/10], iteration [38/501] Loss: 9.6544\n",
      "Epoch [1/10], iteration [39/501] Loss: 9.6534\n",
      "Epoch [1/10], iteration [40/501] Loss: 9.4034\n",
      "Epoch [1/10], iteration [41/501] Loss: 8.8737\n",
      "Epoch [1/10], iteration [42/501] Loss: 8.9041\n",
      "Epoch [1/10], iteration [43/501] Loss: 8.7415\n",
      "Epoch [1/10], iteration [44/501] Loss: 8.7273\n",
      "Epoch [1/10], iteration [45/501] Loss: 8.4175\n",
      "Epoch [1/10], iteration [46/501] Loss: 8.2970\n",
      "Epoch [1/10], iteration [47/501] Loss: 8.1953\n",
      "Epoch [1/10], iteration [48/501] Loss: 8.2408\n",
      "Epoch [1/10], iteration [49/501] Loss: 8.1347\n",
      "Epoch [1/10], iteration [50/501] Loss: 7.9794\n",
      "Epoch [1/10], iteration [51/501] Loss: 7.9614\n",
      "Epoch [1/10], iteration [52/501] Loss: 7.9582\n",
      "Epoch [1/10], iteration [53/501] Loss: 7.8940\n",
      "Epoch [1/10], iteration [54/501] Loss: 7.8462\n",
      "Epoch [1/10], iteration [55/501] Loss: 7.8479\n",
      "Epoch [1/10], iteration [56/501] Loss: 7.8299\n",
      "Epoch [1/10], iteration [57/501] Loss: 7.8282\n",
      "Epoch [1/10], iteration [58/501] Loss: 7.7946\n",
      "Epoch [1/10], iteration [59/501] Loss: 7.8020\n",
      "Epoch [1/10], iteration [60/501] Loss: 7.7978\n",
      "Epoch [1/10], iteration [61/501] Loss: 7.7947\n",
      "Epoch [1/10], iteration [62/501] Loss: 7.7900\n",
      "Epoch [1/10], iteration [63/501] Loss: 7.7935\n",
      "Epoch [1/10], iteration [64/501] Loss: 7.7798\n",
      "Epoch [1/10], iteration [65/501] Loss: 7.7789\n",
      "Epoch [1/10], iteration [66/501] Loss: 7.7692\n",
      "Epoch [1/10], iteration [67/501] Loss: 7.7693\n",
      "Epoch [1/10], iteration [68/501] Loss: 7.7766\n",
      "Epoch [1/10], iteration [69/501] Loss: 7.7724\n",
      "Epoch [1/10], iteration [70/501] Loss: 7.7752\n",
      "Epoch [1/10], iteration [71/501] Loss: 7.7615\n",
      "Epoch [1/10], iteration [72/501] Loss: 7.7737\n",
      "Epoch [1/10], iteration [73/501] Loss: 7.7765\n",
      "Epoch [1/10], iteration [74/501] Loss: 7.7696\n",
      "Epoch [1/10], iteration [75/501] Loss: 7.7693\n",
      "Epoch [1/10], iteration [76/501] Loss: 7.7694\n",
      "Epoch [1/10], iteration [77/501] Loss: 7.7613\n",
      "Epoch [1/10], iteration [78/501] Loss: 7.7653\n",
      "Epoch [1/10], iteration [79/501] Loss: 7.7888\n",
      "Epoch [1/10], iteration [80/501] Loss: 7.7655\n",
      "Epoch [1/10], iteration [81/501] Loss: 7.7667\n",
      "Epoch [1/10], iteration [82/501] Loss: 7.7685\n",
      "Epoch [1/10], iteration [83/501] Loss: 7.7680\n",
      "Epoch [1/10], iteration [84/501] Loss: 7.7644\n",
      "Epoch [1/10], iteration [85/501] Loss: 7.7761\n",
      "Epoch [1/10], iteration [86/501] Loss: 7.7690\n",
      "Epoch [1/10], iteration [87/501] Loss: 7.7709\n",
      "Epoch [1/10], iteration [88/501] Loss: 7.7652\n",
      "Epoch [1/10], iteration [89/501] Loss: 7.7669\n",
      "Epoch [1/10], iteration [90/501] Loss: 7.7645\n",
      "Epoch [1/10], iteration [91/501] Loss: 7.7586\n",
      "Epoch [1/10], iteration [92/501] Loss: 7.7651\n",
      "Epoch [1/10], iteration [93/501] Loss: 7.7637\n",
      "Epoch [1/10], iteration [94/501] Loss: 7.7648\n",
      "Epoch [1/10], iteration [95/501] Loss: 7.7700\n",
      "Epoch [1/10], iteration [96/501] Loss: 7.7532\n",
      "Epoch [1/10], iteration [97/501] Loss: 7.7633\n",
      "Epoch [1/10], iteration [98/501] Loss: 7.7715\n",
      "Epoch [1/10], iteration [99/501] Loss: 7.7597\n",
      "Epoch [1/10], iteration [100/501] Loss: 7.7625\n",
      "Epoch [1/10], iteration [101/501] Loss: 7.7636\n",
      "Epoch [1/10], iteration [102/501] Loss: 7.7597\n",
      "Epoch [1/10], iteration [103/501] Loss: 7.7578\n",
      "Epoch [1/10], iteration [104/501] Loss: 7.7563\n",
      "Epoch [1/10], iteration [105/501] Loss: 7.7525\n",
      "Epoch [1/10], iteration [106/501] Loss: 7.7528\n",
      "Epoch [1/10], iteration [107/501] Loss: 7.7496\n",
      "Epoch [1/10], iteration [108/501] Loss: 7.7563\n",
      "Epoch [1/10], iteration [109/501] Loss: 7.7499\n",
      "Epoch [1/10], iteration [110/501] Loss: 7.7345\n",
      "Epoch [1/10], iteration [111/501] Loss: 7.7398\n",
      "Epoch [1/10], iteration [112/501] Loss: 7.7286\n",
      "Epoch [1/10], iteration [113/501] Loss: 7.7226\n",
      "Epoch [1/10], iteration [114/501] Loss: 7.7180\n",
      "Epoch [1/10], iteration [115/501] Loss: 7.7139\n",
      "Epoch [1/10], iteration [116/501] Loss: 7.7294\n",
      "Epoch [1/10], iteration [117/501] Loss: 7.7377\n",
      "Epoch [1/10], iteration [118/501] Loss: 7.7170\n",
      "Epoch [1/10], iteration [119/501] Loss: 7.7065\n",
      "Epoch [1/10], iteration [120/501] Loss: 7.7071\n",
      "Epoch [1/10], iteration [121/501] Loss: 7.7004\n",
      "Epoch [1/10], iteration [122/501] Loss: 7.7346\n",
      "Epoch [1/10], iteration [123/501] Loss: 7.7138\n",
      "Epoch [1/10], iteration [124/501] Loss: 7.7119\n",
      "Epoch [1/10], iteration [125/501] Loss: 7.7133\n",
      "Epoch [1/10], iteration [126/501] Loss: 7.6737\n",
      "Epoch [1/10], iteration [127/501] Loss: 7.7021\n",
      "Epoch [1/10], iteration [128/501] Loss: 7.6653\n",
      "Epoch [1/10], iteration [129/501] Loss: 7.6529\n",
      "Epoch [1/10], iteration [130/501] Loss: 7.6724\n",
      "Epoch [1/10], iteration [131/501] Loss: 7.6729\n",
      "Epoch [1/10], iteration [132/501] Loss: 7.6782\n",
      "Epoch [1/10], iteration [133/501] Loss: 7.6289\n",
      "Epoch [1/10], iteration [134/501] Loss: 7.6538\n",
      "Epoch [1/10], iteration [135/501] Loss: 7.6514\n",
      "Epoch [1/10], iteration [136/501] Loss: 7.6103\n",
      "Epoch [1/10], iteration [137/501] Loss: 7.6394\n",
      "Epoch [1/10], iteration [138/501] Loss: 7.5770\n",
      "Epoch [1/10], iteration [139/501] Loss: 7.6300\n",
      "Epoch [1/10], iteration [140/501] Loss: 7.6167\n",
      "Epoch [1/10], iteration [141/501] Loss: 7.6159\n",
      "Epoch [1/10], iteration [142/501] Loss: 7.6291\n",
      "Epoch [1/10], iteration [143/501] Loss: 7.5788\n",
      "Epoch [1/10], iteration [144/501] Loss: 7.5911\n",
      "Epoch [1/10], iteration [145/501] Loss: 7.5529\n",
      "Epoch [1/10], iteration [146/501] Loss: 7.5538\n",
      "Epoch [1/10], iteration [147/501] Loss: 7.5325\n",
      "Epoch [1/10], iteration [148/501] Loss: 7.5563\n",
      "Epoch [1/10], iteration [149/501] Loss: 7.5643\n",
      "Epoch [1/10], iteration [150/501] Loss: 7.5289\n",
      "Epoch [1/10], iteration [151/501] Loss: 7.5251\n",
      "Epoch [1/10], iteration [152/501] Loss: 7.5444\n",
      "Epoch [1/10], iteration [153/501] Loss: 7.5152\n",
      "Epoch [1/10], iteration [154/501] Loss: 7.5651\n",
      "Epoch [1/10], iteration [155/501] Loss: 7.5052\n",
      "Epoch [1/10], iteration [156/501] Loss: 7.4876\n",
      "Epoch [1/10], iteration [157/501] Loss: 7.4269\n",
      "Epoch [1/10], iteration [158/501] Loss: 7.4830\n",
      "Epoch [1/10], iteration [159/501] Loss: 7.4758\n",
      "Epoch [1/10], iteration [160/501] Loss: 7.4704\n",
      "Epoch [1/10], iteration [161/501] Loss: 7.4133\n",
      "Epoch [1/10], iteration [162/501] Loss: 7.4210\n",
      "Epoch [1/10], iteration [163/501] Loss: 7.4708\n",
      "Epoch [1/10], iteration [164/501] Loss: 7.4056\n",
      "Epoch [1/10], iteration [165/501] Loss: 7.4416\n",
      "Epoch [1/10], iteration [166/501] Loss: 7.4052\n",
      "Epoch [1/10], iteration [167/501] Loss: 7.3685\n",
      "Epoch [1/10], iteration [168/501] Loss: 7.3530\n",
      "Epoch [1/10], iteration [169/501] Loss: 7.3907\n",
      "Epoch [1/10], iteration [170/501] Loss: 7.3264\n",
      "Epoch [1/10], iteration [171/501] Loss: 7.3936\n",
      "Epoch [1/10], iteration [172/501] Loss: 7.3452\n",
      "Epoch [1/10], iteration [173/501] Loss: 7.3003\n",
      "Epoch [1/10], iteration [174/501] Loss: 7.3324\n",
      "Epoch [1/10], iteration [175/501] Loss: 7.3177\n",
      "Epoch [1/10], iteration [176/501] Loss: 7.2996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], iteration [177/501] Loss: 7.2353\n",
      "Epoch [1/10], iteration [178/501] Loss: 7.2632\n",
      "Epoch [1/10], iteration [179/501] Loss: 7.2854\n",
      "Epoch [1/10], iteration [180/501] Loss: 7.1083\n",
      "Epoch [1/10], iteration [181/501] Loss: 7.2463\n",
      "Epoch [1/10], iteration [182/501] Loss: 7.1578\n",
      "Epoch [1/10], iteration [183/501] Loss: 7.2414\n",
      "Epoch [1/10], iteration [184/501] Loss: 7.2470\n",
      "Epoch [1/10], iteration [185/501] Loss: 7.1710\n",
      "Epoch [1/10], iteration [186/501] Loss: 7.1698\n",
      "Epoch [1/10], iteration [187/501] Loss: 7.1697\n",
      "Epoch [1/10], iteration [188/501] Loss: 7.1680\n",
      "Epoch [1/10], iteration [189/501] Loss: 7.1455\n",
      "Epoch [1/10], iteration [190/501] Loss: 7.1589\n",
      "Epoch [1/10], iteration [191/501] Loss: 7.0815\n",
      "Epoch [1/10], iteration [192/501] Loss: 7.1554\n",
      "Epoch [1/10], iteration [193/501] Loss: 7.0172\n",
      "Epoch [1/10], iteration [194/501] Loss: 7.0171\n",
      "Epoch [1/10], iteration [195/501] Loss: 6.9331\n",
      "Epoch [1/10], iteration [196/501] Loss: 6.9752\n",
      "Epoch [1/10], iteration [197/501] Loss: 7.0257\n",
      "Epoch [1/10], iteration [198/501] Loss: 6.9669\n",
      "Epoch [1/10], iteration [199/501] Loss: 6.9376\n",
      "Epoch [1/10], iteration [200/501] Loss: 7.0422\n",
      "Epoch [1/10], iteration [201/501] Loss: 6.9430\n",
      "Epoch [1/10], iteration [202/501] Loss: 6.8341\n",
      "Epoch [1/10], iteration [203/501] Loss: 6.9187\n",
      "Epoch [1/10], iteration [204/501] Loss: 6.8187\n",
      "Epoch [1/10], iteration [205/501] Loss: 6.8730\n",
      "Epoch [1/10], iteration [206/501] Loss: 6.7612\n",
      "Epoch [1/10], iteration [207/501] Loss: 6.7555\n",
      "Epoch [1/10], iteration [208/501] Loss: 6.7649\n",
      "Epoch [1/10], iteration [209/501] Loss: 6.6961\n",
      "Epoch [1/10], iteration [210/501] Loss: 6.7088\n",
      "Epoch [1/10], iteration [211/501] Loss: 6.7747\n",
      "Epoch [1/10], iteration [212/501] Loss: 6.6577\n",
      "Epoch [1/10], iteration [213/501] Loss: 6.6070\n",
      "Epoch [1/10], iteration [214/501] Loss: 6.6883\n",
      "Epoch [1/10], iteration [215/501] Loss: 6.6038\n",
      "Epoch [1/10], iteration [216/501] Loss: 6.5224\n",
      "Epoch [1/10], iteration [217/501] Loss: 6.4986\n",
      "Epoch [1/10], iteration [218/501] Loss: 6.3968\n",
      "Epoch [1/10], iteration [219/501] Loss: 6.4368\n",
      "Epoch [1/10], iteration [220/501] Loss: 6.5138\n",
      "Epoch [1/10], iteration [221/501] Loss: 6.4314\n",
      "Epoch [1/10], iteration [222/501] Loss: 6.3722\n",
      "Epoch [1/10], iteration [223/501] Loss: 6.3389\n",
      "Epoch [1/10], iteration [224/501] Loss: 6.3413\n",
      "Epoch [1/10], iteration [225/501] Loss: 6.2679\n",
      "Epoch [1/10], iteration [226/501] Loss: 6.2941\n",
      "Epoch [1/10], iteration [227/501] Loss: 6.1983\n",
      "Epoch [1/10], iteration [228/501] Loss: 6.2651\n",
      "Epoch [1/10], iteration [229/501] Loss: 6.2377\n",
      "Epoch [1/10], iteration [230/501] Loss: 6.2916\n",
      "Epoch [1/10], iteration [231/501] Loss: 6.1011\n",
      "Epoch [1/10], iteration [232/501] Loss: 6.1238\n",
      "Epoch [1/10], iteration [233/501] Loss: 6.1656\n",
      "Epoch [1/10], iteration [234/501] Loss: 6.0602\n",
      "Epoch [1/10], iteration [235/501] Loss: 6.1609\n",
      "Epoch [1/10], iteration [236/501] Loss: 6.0518\n",
      "Epoch [1/10], iteration [237/501] Loss: 6.0780\n",
      "Epoch [1/10], iteration [238/501] Loss: 6.0315\n",
      "Epoch [1/10], iteration [239/501] Loss: 6.0564\n",
      "Epoch [1/10], iteration [240/501] Loss: 5.9214\n",
      "Epoch [1/10], iteration [241/501] Loss: 6.0541\n",
      "Epoch [1/10], iteration [242/501] Loss: 6.0696\n",
      "Epoch [1/10], iteration [243/501] Loss: 5.9210\n",
      "Epoch [1/10], iteration [244/501] Loss: 5.9372\n",
      "Epoch [1/10], iteration [245/501] Loss: 6.0309\n",
      "Epoch [1/10], iteration [246/501] Loss: 5.8931\n",
      "Epoch [1/10], iteration [247/501] Loss: 5.8117\n",
      "Epoch [1/10], iteration [248/501] Loss: 5.8638\n",
      "Epoch [1/10], iteration [249/501] Loss: 5.8668\n",
      "Epoch [1/10], iteration [250/501] Loss: 5.7375\n",
      "Epoch [1/10], iteration [251/501] Loss: 5.7620\n",
      "Epoch [1/10], iteration [252/501] Loss: 5.5913\n",
      "Epoch [1/10], iteration [253/501] Loss: 5.7096\n",
      "Epoch [1/10], iteration [254/501] Loss: 5.7674\n",
      "Epoch [1/10], iteration [255/501] Loss: 5.7084\n",
      "Epoch [1/10], iteration [256/501] Loss: 5.6368\n",
      "Epoch [1/10], iteration [257/501] Loss: 5.5449\n",
      "Epoch [1/10], iteration [258/501] Loss: 5.7139\n",
      "Epoch [1/10], iteration [259/501] Loss: 5.4808\n",
      "Epoch [1/10], iteration [260/501] Loss: 5.5875\n",
      "Epoch [1/10], iteration [261/501] Loss: 5.6188\n",
      "Epoch [1/10], iteration [262/501] Loss: 5.4467\n",
      "Epoch [1/10], iteration [263/501] Loss: 5.3604\n",
      "Epoch [1/10], iteration [264/501] Loss: 5.4587\n",
      "Epoch [1/10], iteration [265/501] Loss: 5.4319\n",
      "Epoch [1/10], iteration [266/501] Loss: 5.4744\n",
      "Epoch [1/10], iteration [267/501] Loss: 5.3314\n",
      "Epoch [1/10], iteration [268/501] Loss: 5.2052\n",
      "Epoch [1/10], iteration [269/501] Loss: 5.3541\n",
      "Epoch [1/10], iteration [270/501] Loss: 5.2425\n",
      "Epoch [1/10], iteration [271/501] Loss: 5.2549\n",
      "Epoch [1/10], iteration [272/501] Loss: 5.1414\n",
      "Epoch [1/10], iteration [273/501] Loss: 5.1958\n",
      "Epoch [1/10], iteration [274/501] Loss: 5.1949\n",
      "Epoch [1/10], iteration [275/501] Loss: 5.2165\n",
      "Epoch [1/10], iteration [276/501] Loss: 5.0403\n",
      "Epoch [1/10], iteration [277/501] Loss: 5.2177\n",
      "Epoch [1/10], iteration [278/501] Loss: 5.1148\n",
      "Epoch [1/10], iteration [279/501] Loss: 5.0194\n",
      "Epoch [1/10], iteration [280/501] Loss: 5.0805\n",
      "Epoch [1/10], iteration [281/501] Loss: 4.9196\n",
      "Epoch [1/10], iteration [282/501] Loss: 5.0405\n",
      "Epoch [1/10], iteration [283/501] Loss: 4.8615\n",
      "Epoch [1/10], iteration [284/501] Loss: 4.8521\n",
      "Epoch [1/10], iteration [285/501] Loss: 4.8423\n",
      "Epoch [1/10], iteration [286/501] Loss: 4.7820\n",
      "Epoch [1/10], iteration [287/501] Loss: 4.9268\n",
      "Epoch [1/10], iteration [288/501] Loss: 4.7715\n",
      "Epoch [1/10], iteration [289/501] Loss: 4.7958\n",
      "Epoch [1/10], iteration [290/501] Loss: 4.9021\n",
      "Epoch [1/10], iteration [291/501] Loss: 4.7968\n",
      "Epoch [1/10], iteration [292/501] Loss: 4.6690\n",
      "Epoch [1/10], iteration [293/501] Loss: 4.7738\n",
      "Epoch [1/10], iteration [294/501] Loss: 4.7341\n",
      "Epoch [1/10], iteration [295/501] Loss: 4.7970\n",
      "Epoch [1/10], iteration [296/501] Loss: 4.5772\n",
      "Epoch [1/10], iteration [297/501] Loss: 4.7836\n",
      "Epoch [1/10], iteration [298/501] Loss: 4.4661\n",
      "Epoch [1/10], iteration [299/501] Loss: 4.7179\n",
      "Epoch [1/10], iteration [300/501] Loss: 4.4582\n",
      "Epoch [1/10], iteration [301/501] Loss: 4.3704\n",
      "Epoch [1/10], iteration [302/501] Loss: 4.4505\n",
      "Epoch [1/10], iteration [303/501] Loss: 4.3148\n",
      "Epoch [1/10], iteration [304/501] Loss: 4.4384\n",
      "Epoch [1/10], iteration [305/501] Loss: 4.2880\n",
      "Epoch [1/10], iteration [306/501] Loss: 4.3269\n",
      "Epoch [1/10], iteration [307/501] Loss: 4.3428\n",
      "Epoch [1/10], iteration [308/501] Loss: 4.2573\n",
      "Epoch [1/10], iteration [309/501] Loss: 4.2327\n",
      "Epoch [1/10], iteration [310/501] Loss: 4.1517\n",
      "Epoch [1/10], iteration [311/501] Loss: 4.1257\n",
      "Epoch [1/10], iteration [312/501] Loss: 3.9478\n",
      "Epoch [1/10], iteration [313/501] Loss: 4.1437\n",
      "Epoch [1/10], iteration [314/501] Loss: 3.9473\n",
      "Epoch [1/10], iteration [315/501] Loss: 4.1138\n",
      "Epoch [1/10], iteration [316/501] Loss: 3.9250\n",
      "Epoch [1/10], iteration [317/501] Loss: 3.9239\n",
      "Epoch [1/10], iteration [318/501] Loss: 4.0362\n",
      "Epoch [1/10], iteration [319/501] Loss: 3.8799\n",
      "Epoch [1/10], iteration [320/501] Loss: 3.9433\n",
      "Epoch [1/10], iteration [321/501] Loss: 3.8053\n",
      "Epoch [1/10], iteration [322/501] Loss: 3.6436\n",
      "Epoch [1/10], iteration [323/501] Loss: 3.7717\n",
      "Epoch [1/10], iteration [324/501] Loss: 3.7014\n",
      "Epoch [1/10], iteration [325/501] Loss: 3.7608\n",
      "Epoch [1/10], iteration [326/501] Loss: 3.7438\n",
      "Epoch [1/10], iteration [327/501] Loss: 3.5834\n",
      "Epoch [1/10], iteration [328/501] Loss: 3.7112\n",
      "Epoch [1/10], iteration [329/501] Loss: 3.4806\n",
      "Epoch [1/10], iteration [330/501] Loss: 3.5604\n",
      "Epoch [1/10], iteration [331/501] Loss: 3.4019\n",
      "Epoch [1/10], iteration [332/501] Loss: 3.6198\n",
      "Epoch [1/10], iteration [333/501] Loss: 3.4974\n",
      "Epoch [1/10], iteration [334/501] Loss: 3.3372\n",
      "Epoch [1/10], iteration [335/501] Loss: 3.3821\n",
      "Epoch [1/10], iteration [336/501] Loss: 3.4686\n",
      "Epoch [1/10], iteration [337/501] Loss: 3.4402\n",
      "Epoch [1/10], iteration [338/501] Loss: 3.3777\n",
      "Epoch [1/10], iteration [339/501] Loss: 3.3235\n",
      "Epoch [1/10], iteration [340/501] Loss: 3.2695\n",
      "Epoch [1/10], iteration [341/501] Loss: 3.2385\n",
      "Epoch [1/10], iteration [342/501] Loss: 3.2806\n",
      "Epoch [1/10], iteration [343/501] Loss: 3.1435\n",
      "Epoch [1/10], iteration [344/501] Loss: 3.1735\n",
      "Epoch [1/10], iteration [345/501] Loss: 3.1483\n",
      "Epoch [1/10], iteration [346/501] Loss: 3.1659\n",
      "Epoch [1/10], iteration [347/501] Loss: 3.1839\n",
      "Epoch [1/10], iteration [348/501] Loss: 3.1927\n",
      "Epoch [1/10], iteration [349/501] Loss: 3.0000\n",
      "Epoch [1/10], iteration [350/501] Loss: 3.1250\n",
      "Epoch [1/10], iteration [351/501] Loss: 2.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], iteration [352/501] Loss: 2.8735\n",
      "Epoch [1/10], iteration [353/501] Loss: 2.9156\n",
      "Epoch [1/10], iteration [354/501] Loss: 2.9178\n",
      "Epoch [1/10], iteration [355/501] Loss: 2.9068\n",
      "Epoch [1/10], iteration [356/501] Loss: 2.8184\n",
      "Epoch [1/10], iteration [357/501] Loss: 2.7864\n",
      "Epoch [1/10], iteration [358/501] Loss: 2.8371\n",
      "Epoch [1/10], iteration [359/501] Loss: 2.7650\n",
      "Epoch [1/10], iteration [360/501] Loss: 2.6528\n",
      "Epoch [1/10], iteration [361/501] Loss: 2.6944\n",
      "Epoch [1/10], iteration [362/501] Loss: 2.6955\n",
      "Epoch [1/10], iteration [363/501] Loss: 2.6307\n",
      "Epoch [1/10], iteration [364/501] Loss: 2.6076\n",
      "Epoch [1/10], iteration [365/501] Loss: 2.6115\n",
      "Epoch [1/10], iteration [366/501] Loss: 2.6787\n",
      "Epoch [1/10], iteration [367/501] Loss: 2.6628\n",
      "Epoch [1/10], iteration [368/501] Loss: 2.6732\n",
      "Epoch [1/10], iteration [369/501] Loss: 2.4472\n",
      "Epoch [1/10], iteration [370/501] Loss: 2.5337\n",
      "Epoch [1/10], iteration [371/501] Loss: 2.6163\n",
      "Epoch [1/10], iteration [372/501] Loss: 2.4324\n",
      "Epoch [1/10], iteration [373/501] Loss: 2.4108\n",
      "Epoch [1/10], iteration [374/501] Loss: 2.3730\n",
      "Epoch [1/10], iteration [375/501] Loss: 2.3259\n",
      "Epoch [1/10], iteration [376/501] Loss: 2.2858\n",
      "Epoch [1/10], iteration [377/501] Loss: 2.4516\n",
      "Epoch [1/10], iteration [378/501] Loss: 2.2676\n",
      "Epoch [1/10], iteration [379/501] Loss: 2.3110\n",
      "Epoch [1/10], iteration [380/501] Loss: 2.2436\n",
      "Epoch [1/10], iteration [381/501] Loss: 2.1046\n",
      "Epoch [1/10], iteration [382/501] Loss: 2.1824\n",
      "Epoch [1/10], iteration [383/501] Loss: 2.0987\n",
      "Epoch [1/10], iteration [384/501] Loss: 2.1783\n",
      "Epoch [1/10], iteration [385/501] Loss: 2.1482\n",
      "Epoch [1/10], iteration [386/501] Loss: 2.1524\n",
      "Epoch [1/10], iteration [387/501] Loss: 2.2272\n",
      "Epoch [1/10], iteration [388/501] Loss: 2.1438\n",
      "Epoch [1/10], iteration [389/501] Loss: 2.1225\n",
      "Epoch [1/10], iteration [390/501] Loss: 1.9390\n",
      "Epoch [1/10], iteration [391/501] Loss: 2.0152\n",
      "Epoch [1/10], iteration [392/501] Loss: 2.0715\n",
      "Epoch [1/10], iteration [393/501] Loss: 2.0809\n",
      "Epoch [1/10], iteration [394/501] Loss: 2.0515\n",
      "Epoch [1/10], iteration [395/501] Loss: 2.0363\n",
      "Epoch [1/10], iteration [396/501] Loss: 1.9045\n",
      "Epoch [1/10], iteration [397/501] Loss: 1.9253\n",
      "Epoch [1/10], iteration [398/501] Loss: 1.9627\n",
      "Epoch [1/10], iteration [399/501] Loss: 1.8089\n",
      "Epoch [1/10], iteration [400/501] Loss: 1.9043\n",
      "Epoch [1/10], iteration [401/501] Loss: 1.8221\n",
      "Epoch [1/10], iteration [402/501] Loss: 1.7023\n",
      "Epoch [1/10], iteration [403/501] Loss: 1.7539\n",
      "Epoch [1/10], iteration [404/501] Loss: 1.6408\n",
      "Epoch [1/10], iteration [405/501] Loss: 1.8327\n",
      "Epoch [1/10], iteration [406/501] Loss: 1.7712\n",
      "Epoch [1/10], iteration [407/501] Loss: 1.6196\n",
      "Epoch [1/10], iteration [408/501] Loss: 1.7741\n",
      "Epoch [1/10], iteration [409/501] Loss: 1.7022\n",
      "Epoch [1/10], iteration [410/501] Loss: 1.7124\n",
      "Epoch [1/10], iteration [411/501] Loss: 1.6784\n",
      "Epoch [1/10], iteration [412/501] Loss: 1.7631\n",
      "Epoch [1/10], iteration [413/501] Loss: 1.6382\n",
      "Epoch [1/10], iteration [414/501] Loss: 1.5963\n",
      "Epoch [1/10], iteration [415/501] Loss: 1.5784\n",
      "Epoch [1/10], iteration [416/501] Loss: 1.6073\n",
      "Epoch [1/10], iteration [417/501] Loss: 1.5153\n",
      "Epoch [1/10], iteration [418/501] Loss: 1.5817\n",
      "Epoch [1/10], iteration [419/501] Loss: 1.4487\n",
      "Epoch [1/10], iteration [420/501] Loss: 1.3796\n",
      "Epoch [1/10], iteration [421/501] Loss: 1.5111\n",
      "Epoch [1/10], iteration [422/501] Loss: 1.4902\n",
      "Epoch [1/10], iteration [423/501] Loss: 1.4187\n",
      "Epoch [1/10], iteration [424/501] Loss: 1.5011\n",
      "Epoch [1/10], iteration [425/501] Loss: 1.4387\n",
      "Epoch [1/10], iteration [426/501] Loss: 1.5452\n",
      "Epoch [1/10], iteration [427/501] Loss: 1.5609\n",
      "Epoch [1/10], iteration [428/501] Loss: 1.4554\n",
      "Epoch [1/10], iteration [429/501] Loss: 1.4381\n",
      "Epoch [1/10], iteration [430/501] Loss: 1.3557\n",
      "Epoch [1/10], iteration [431/501] Loss: 1.2422\n",
      "Epoch [1/10], iteration [432/501] Loss: 1.3302\n",
      "Epoch [1/10], iteration [433/501] Loss: 1.3432\n",
      "Epoch [1/10], iteration [434/501] Loss: 1.3131\n",
      "Epoch [1/10], iteration [435/501] Loss: 1.2692\n",
      "Epoch [1/10], iteration [436/501] Loss: 1.3938\n",
      "Epoch [1/10], iteration [437/501] Loss: 1.1678\n",
      "Epoch [1/10], iteration [438/501] Loss: 1.2991\n",
      "Epoch [1/10], iteration [439/501] Loss: 1.2675\n",
      "Epoch [1/10], iteration [440/501] Loss: 1.2060\n",
      "Epoch [1/10], iteration [441/501] Loss: 1.3392\n",
      "Epoch [1/10], iteration [442/501] Loss: 1.2779\n",
      "Epoch [1/10], iteration [443/501] Loss: 1.0934\n",
      "Epoch [1/10], iteration [444/501] Loss: 1.2223\n",
      "Epoch [1/10], iteration [445/501] Loss: 1.1792\n",
      "Epoch [1/10], iteration [446/501] Loss: 1.1630\n",
      "Epoch [1/10], iteration [447/501] Loss: 1.1245\n",
      "Epoch [1/10], iteration [448/501] Loss: 1.0408\n",
      "Epoch [1/10], iteration [449/501] Loss: 1.1333\n",
      "Epoch [1/10], iteration [450/501] Loss: 1.2089\n",
      "Epoch [1/10], iteration [451/501] Loss: 1.1913\n",
      "Epoch [1/10], iteration [452/501] Loss: 1.0965\n",
      "Epoch [1/10], iteration [453/501] Loss: 1.1844\n",
      "Epoch [1/10], iteration [454/501] Loss: 1.1341\n",
      "Epoch [1/10], iteration [455/501] Loss: 1.0455\n",
      "Epoch [1/10], iteration [456/501] Loss: 0.9945\n",
      "Epoch [1/10], iteration [457/501] Loss: 1.0953\n",
      "Epoch [1/10], iteration [458/501] Loss: 1.0346\n",
      "Epoch [1/10], iteration [459/501] Loss: 1.0195\n",
      "Epoch [1/10], iteration [460/501] Loss: 0.9436\n",
      "Epoch [1/10], iteration [461/501] Loss: 0.9901\n",
      "Epoch [1/10], iteration [462/501] Loss: 0.9534\n",
      "Epoch [1/10], iteration [463/501] Loss: 0.9630\n",
      "Epoch [1/10], iteration [464/501] Loss: 0.9362\n",
      "Epoch [1/10], iteration [465/501] Loss: 0.9317\n",
      "Epoch [1/10], iteration [466/501] Loss: 1.0330\n",
      "Epoch [1/10], iteration [467/501] Loss: 1.0222\n",
      "Epoch [1/10], iteration [468/501] Loss: 0.9829\n",
      "Epoch [1/10], iteration [469/501] Loss: 0.9466\n",
      "Epoch [1/10], iteration [470/501] Loss: 0.9678\n",
      "Epoch [1/10], iteration [471/501] Loss: 0.9597\n",
      "Epoch [1/10], iteration [472/501] Loss: 0.8737\n",
      "Epoch [1/10], iteration [473/501] Loss: 0.9338\n",
      "Epoch [1/10], iteration [474/501] Loss: 0.9361\n",
      "Epoch [1/10], iteration [475/501] Loss: 0.9796\n",
      "Epoch [1/10], iteration [476/501] Loss: 0.8321\n",
      "Epoch [1/10], iteration [477/501] Loss: 0.8691\n",
      "Epoch [1/10], iteration [478/501] Loss: 0.8943\n",
      "Epoch [1/10], iteration [479/501] Loss: 0.8841\n",
      "Epoch [1/10], iteration [480/501] Loss: 0.8191\n",
      "Epoch [1/10], iteration [481/501] Loss: 0.8618\n",
      "Epoch [1/10], iteration [482/501] Loss: 0.7909\n",
      "Epoch [1/10], iteration [483/501] Loss: 0.8435\n",
      "Epoch [1/10], iteration [484/501] Loss: 0.8903\n",
      "Epoch [1/10], iteration [485/501] Loss: 0.8089\n",
      "Epoch [1/10], iteration [486/501] Loss: 0.8063\n",
      "Epoch [1/10], iteration [487/501] Loss: 0.8056\n",
      "Epoch [1/10], iteration [488/501] Loss: 0.7756\n",
      "Epoch [1/10], iteration [489/501] Loss: 0.8281\n",
      "Epoch [1/10], iteration [490/501] Loss: 0.8485\n",
      "Epoch [1/10], iteration [491/501] Loss: 0.7409\n",
      "Epoch [1/10], iteration [492/501] Loss: 0.8057\n",
      "Epoch [1/10], iteration [493/501] Loss: 0.7370\n",
      "Epoch [1/10], iteration [494/501] Loss: 0.8087\n",
      "Epoch [1/10], iteration [495/501] Loss: 0.6876\n",
      "Epoch [1/10], iteration [496/501] Loss: 0.7944\n",
      "Epoch [1/10], iteration [497/501] Loss: 0.8414\n",
      "Epoch [1/10], iteration [498/501] Loss: 0.7217\n",
      "Epoch [1/10], iteration [499/501] Loss: 0.6410\n",
      "Epoch [1/10], iteration [500/501] Loss: 0.6766\n",
      "Epoch [1/10], iteration [501/501] Loss: 0.6017\n",
      "Epoch [1/10], Test Accuracy of the model on the 2350 test images: 65.36170212765957 %\n",
      "Epoch [2/10], iteration [1/501] Loss: 0.7343\n",
      "Epoch [2/10], iteration [2/501] Loss: 0.7510\n",
      "Epoch [2/10], iteration [3/501] Loss: 0.6985\n",
      "Epoch [2/10], iteration [4/501] Loss: 0.7715\n",
      "Epoch [2/10], iteration [5/501] Loss: 0.7560\n",
      "Epoch [2/10], iteration [6/501] Loss: 0.7172\n",
      "Epoch [2/10], iteration [7/501] Loss: 0.6527\n",
      "Epoch [2/10], iteration [8/501] Loss: 0.7312\n",
      "Epoch [2/10], iteration [9/501] Loss: 0.7866\n",
      "Epoch [2/10], iteration [10/501] Loss: 0.7047\n",
      "Epoch [2/10], iteration [11/501] Loss: 0.6392\n",
      "Epoch [2/10], iteration [12/501] Loss: 0.6108\n",
      "Epoch [2/10], iteration [13/501] Loss: 0.6080\n",
      "Epoch [2/10], iteration [14/501] Loss: 0.6042\n",
      "Epoch [2/10], iteration [15/501] Loss: 0.5951\n",
      "Epoch [2/10], iteration [16/501] Loss: 0.5590\n",
      "Epoch [2/10], iteration [17/501] Loss: 0.5678\n",
      "Epoch [2/10], iteration [18/501] Loss: 0.5747\n",
      "Epoch [2/10], iteration [19/501] Loss: 0.5553\n",
      "Epoch [2/10], iteration [20/501] Loss: 0.7097\n",
      "Epoch [2/10], iteration [21/501] Loss: 0.5953\n",
      "Epoch [2/10], iteration [22/501] Loss: 0.6120\n",
      "Epoch [2/10], iteration [23/501] Loss: 0.6452\n",
      "Epoch [2/10], iteration [24/501] Loss: 0.6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], iteration [25/501] Loss: 0.5267\n",
      "Epoch [2/10], iteration [26/501] Loss: 0.6093\n",
      "Epoch [2/10], iteration [27/501] Loss: 0.6538\n",
      "Epoch [2/10], iteration [28/501] Loss: 0.5363\n",
      "Epoch [2/10], iteration [29/501] Loss: 0.5373\n",
      "Epoch [2/10], iteration [30/501] Loss: 0.4678\n",
      "Epoch [2/10], iteration [31/501] Loss: 0.5266\n",
      "Epoch [2/10], iteration [32/501] Loss: 0.5196\n",
      "Epoch [2/10], iteration [33/501] Loss: 0.5069\n",
      "Epoch [2/10], iteration [34/501] Loss: 0.4691\n",
      "Epoch [2/10], iteration [35/501] Loss: 0.4977\n",
      "Epoch [2/10], iteration [36/501] Loss: 0.5485\n",
      "Epoch [2/10], iteration [37/501] Loss: 0.4962\n",
      "Epoch [2/10], iteration [38/501] Loss: 0.4775\n",
      "Epoch [2/10], iteration [39/501] Loss: 0.4651\n",
      "Epoch [2/10], iteration [40/501] Loss: 0.5343\n",
      "Epoch [2/10], iteration [41/501] Loss: 0.5464\n",
      "Epoch [2/10], iteration [42/501] Loss: 0.4189\n",
      "Epoch [2/10], iteration [43/501] Loss: 0.5244\n",
      "Epoch [2/10], iteration [44/501] Loss: 0.4487\n",
      "Epoch [2/10], iteration [45/501] Loss: 0.4471\n",
      "Epoch [2/10], iteration [46/501] Loss: 0.4502\n",
      "Epoch [2/10], iteration [47/501] Loss: 0.4939\n",
      "Epoch [2/10], iteration [48/501] Loss: 0.4717\n",
      "Epoch [2/10], iteration [49/501] Loss: 0.5337\n",
      "Epoch [2/10], iteration [50/501] Loss: 0.4352\n",
      "Epoch [2/10], iteration [51/501] Loss: 0.5127\n",
      "Epoch [2/10], iteration [52/501] Loss: 0.4357\n",
      "Epoch [2/10], iteration [53/501] Loss: 0.4679\n",
      "Epoch [2/10], iteration [54/501] Loss: 0.4704\n",
      "Epoch [2/10], iteration [55/501] Loss: 0.5214\n",
      "Epoch [2/10], iteration [56/501] Loss: 0.4742\n",
      "Epoch [2/10], iteration [57/501] Loss: 0.4056\n",
      "Epoch [2/10], iteration [58/501] Loss: 0.4353\n",
      "Epoch [2/10], iteration [59/501] Loss: 0.3835\n",
      "Epoch [2/10], iteration [60/501] Loss: 0.3981\n",
      "Epoch [2/10], iteration [61/501] Loss: 0.4681\n",
      "Epoch [2/10], iteration [62/501] Loss: 0.4448\n",
      "Epoch [2/10], iteration [63/501] Loss: 0.3700\n",
      "Epoch [2/10], iteration [64/501] Loss: 0.4713\n",
      "Epoch [2/10], iteration [65/501] Loss: 0.3858\n",
      "Epoch [2/10], iteration [66/501] Loss: 0.4678\n",
      "Epoch [2/10], iteration [67/501] Loss: 0.4168\n",
      "Epoch [2/10], iteration [68/501] Loss: 0.3679\n",
      "Epoch [2/10], iteration [69/501] Loss: 0.4401\n",
      "Epoch [2/10], iteration [70/501] Loss: 0.4822\n",
      "Epoch [2/10], iteration [71/501] Loss: 0.3575\n",
      "Epoch [2/10], iteration [72/501] Loss: 0.4284\n",
      "Epoch [2/10], iteration [73/501] Loss: 0.4427\n",
      "Epoch [2/10], iteration [74/501] Loss: 0.3914\n",
      "Epoch [2/10], iteration [75/501] Loss: 0.4404\n",
      "Epoch [2/10], iteration [76/501] Loss: 0.3732\n",
      "Epoch [2/10], iteration [77/501] Loss: 0.4045\n",
      "Epoch [2/10], iteration [78/501] Loss: 0.3440\n",
      "Epoch [2/10], iteration [79/501] Loss: 0.4391\n",
      "Epoch [2/10], iteration [80/501] Loss: 0.3635\n",
      "Epoch [2/10], iteration [81/501] Loss: 0.3472\n",
      "Epoch [2/10], iteration [82/501] Loss: 0.3372\n",
      "Epoch [2/10], iteration [83/501] Loss: 0.4265\n",
      "Epoch [2/10], iteration [84/501] Loss: 0.4278\n",
      "Epoch [2/10], iteration [85/501] Loss: 0.4232\n",
      "Epoch [2/10], iteration [86/501] Loss: 0.4710\n",
      "Epoch [2/10], iteration [87/501] Loss: 0.3610\n",
      "Epoch [2/10], iteration [88/501] Loss: 0.4036\n",
      "Epoch [2/10], iteration [89/501] Loss: 0.4329\n",
      "Epoch [2/10], iteration [90/501] Loss: 0.4409\n",
      "Epoch [2/10], iteration [91/501] Loss: 0.3809\n",
      "Epoch [2/10], iteration [92/501] Loss: 0.4408\n",
      "Epoch [2/10], iteration [93/501] Loss: 0.3228\n",
      "Epoch [2/10], iteration [94/501] Loss: 0.3557\n",
      "Epoch [2/10], iteration [95/501] Loss: 0.3859\n",
      "Epoch [2/10], iteration [96/501] Loss: 0.3517\n",
      "Epoch [2/10], iteration [97/501] Loss: 0.3767\n",
      "Epoch [2/10], iteration [98/501] Loss: 0.4234\n",
      "Epoch [2/10], iteration [99/501] Loss: 0.3460\n",
      "Epoch [2/10], iteration [100/501] Loss: 0.3761\n",
      "Epoch [2/10], iteration [101/501] Loss: 0.3494\n",
      "Epoch [2/10], iteration [102/501] Loss: 0.3502\n",
      "Epoch [2/10], iteration [103/501] Loss: 0.3433\n",
      "Epoch [2/10], iteration [104/501] Loss: 0.4132\n",
      "Epoch [2/10], iteration [105/501] Loss: 0.3196\n",
      "Epoch [2/10], iteration [106/501] Loss: 0.3218\n",
      "Epoch [2/10], iteration [107/501] Loss: 0.3038\n",
      "Epoch [2/10], iteration [108/501] Loss: 0.3059\n",
      "Epoch [2/10], iteration [109/501] Loss: 0.3181\n",
      "Epoch [2/10], iteration [110/501] Loss: 0.3547\n",
      "Epoch [2/10], iteration [111/501] Loss: 0.3814\n",
      "Epoch [2/10], iteration [112/501] Loss: 0.3256\n",
      "Epoch [2/10], iteration [113/501] Loss: 0.3466\n",
      "Epoch [2/10], iteration [114/501] Loss: 0.3182\n",
      "Epoch [2/10], iteration [115/501] Loss: 0.2869\n",
      "Epoch [2/10], iteration [116/501] Loss: 0.3360\n",
      "Epoch [2/10], iteration [117/501] Loss: 0.2941\n",
      "Epoch [2/10], iteration [118/501] Loss: 0.3339\n",
      "Epoch [2/10], iteration [119/501] Loss: 0.3062\n",
      "Epoch [2/10], iteration [120/501] Loss: 0.2888\n",
      "Epoch [2/10], iteration [121/501] Loss: 0.2927\n",
      "Epoch [2/10], iteration [122/501] Loss: 0.3056\n",
      "Epoch [2/10], iteration [123/501] Loss: 0.2865\n",
      "Epoch [2/10], iteration [124/501] Loss: 0.3630\n",
      "Epoch [2/10], iteration [125/501] Loss: 0.3133\n",
      "Epoch [2/10], iteration [126/501] Loss: 0.2841\n",
      "Epoch [2/10], iteration [127/501] Loss: 0.3292\n",
      "Epoch [2/10], iteration [128/501] Loss: 0.2644\n",
      "Epoch [2/10], iteration [129/501] Loss: 0.2988\n",
      "Epoch [2/10], iteration [130/501] Loss: 0.3101\n",
      "Epoch [2/10], iteration [131/501] Loss: 0.3039\n",
      "Epoch [2/10], iteration [132/501] Loss: 0.3594\n",
      "Epoch [2/10], iteration [133/501] Loss: 0.2827\n",
      "Epoch [2/10], iteration [134/501] Loss: 0.3230\n",
      "Epoch [2/10], iteration [135/501] Loss: 0.2814\n",
      "Epoch [2/10], iteration [136/501] Loss: 0.3198\n",
      "Epoch [2/10], iteration [137/501] Loss: 0.2706\n",
      "Epoch [2/10], iteration [138/501] Loss: 0.2505\n",
      "Epoch [2/10], iteration [139/501] Loss: 0.3015\n",
      "Epoch [2/10], iteration [140/501] Loss: 0.3715\n",
      "Epoch [2/10], iteration [141/501] Loss: 0.3200\n",
      "Epoch [2/10], iteration [142/501] Loss: 0.2420\n",
      "Epoch [2/10], iteration [143/501] Loss: 0.2912\n",
      "Epoch [2/10], iteration [144/501] Loss: 0.3127\n",
      "Epoch [2/10], iteration [145/501] Loss: 0.2731\n",
      "Epoch [2/10], iteration [146/501] Loss: 0.3376\n",
      "Epoch [2/10], iteration [147/501] Loss: 0.2702\n",
      "Epoch [2/10], iteration [148/501] Loss: 0.2919\n",
      "Epoch [2/10], iteration [149/501] Loss: 0.2628\n",
      "Epoch [2/10], iteration [150/501] Loss: 0.2587\n",
      "Epoch [2/10], iteration [151/501] Loss: 0.2201\n",
      "Epoch [2/10], iteration [152/501] Loss: 0.2905\n",
      "Epoch [2/10], iteration [153/501] Loss: 0.2684\n",
      "Epoch [2/10], iteration [154/501] Loss: 0.2844\n",
      "Epoch [2/10], iteration [155/501] Loss: 0.2255\n",
      "Epoch [2/10], iteration [156/501] Loss: 0.2873\n",
      "Epoch [2/10], iteration [157/501] Loss: 0.2523\n",
      "Epoch [2/10], iteration [158/501] Loss: 0.2418\n",
      "Epoch [2/10], iteration [159/501] Loss: 0.2706\n",
      "Epoch [2/10], iteration [160/501] Loss: 0.2486\n",
      "Epoch [2/10], iteration [161/501] Loss: 0.2376\n",
      "Epoch [2/10], iteration [162/501] Loss: 0.2202\n",
      "Epoch [2/10], iteration [163/501] Loss: 0.2937\n",
      "Epoch [2/10], iteration [164/501] Loss: 0.2685\n",
      "Epoch [2/10], iteration [165/501] Loss: 0.2097\n",
      "Epoch [2/10], iteration [166/501] Loss: 0.2927\n",
      "Epoch [2/10], iteration [167/501] Loss: 0.2654\n",
      "Epoch [2/10], iteration [168/501] Loss: 0.2954\n",
      "Epoch [2/10], iteration [169/501] Loss: 0.2441\n",
      "Epoch [2/10], iteration [170/501] Loss: 0.2558\n",
      "Epoch [2/10], iteration [171/501] Loss: 0.1997\n",
      "Epoch [2/10], iteration [172/501] Loss: 0.2808\n",
      "Epoch [2/10], iteration [173/501] Loss: 0.2102\n",
      "Epoch [2/10], iteration [174/501] Loss: 0.2487\n",
      "Epoch [2/10], iteration [175/501] Loss: 0.2472\n",
      "Epoch [2/10], iteration [176/501] Loss: 0.2267\n",
      "Epoch [2/10], iteration [177/501] Loss: 0.2536\n",
      "Epoch [2/10], iteration [178/501] Loss: 0.2966\n",
      "Epoch [2/10], iteration [179/501] Loss: 0.2724\n",
      "Epoch [2/10], iteration [180/501] Loss: 0.2436\n",
      "Epoch [2/10], iteration [181/501] Loss: 0.2686\n",
      "Epoch [2/10], iteration [182/501] Loss: 0.2870\n",
      "Epoch [2/10], iteration [183/501] Loss: 0.2307\n",
      "Epoch [2/10], iteration [184/501] Loss: 0.2493\n",
      "Epoch [2/10], iteration [185/501] Loss: 0.2664\n",
      "Epoch [2/10], iteration [186/501] Loss: 0.2826\n",
      "Epoch [2/10], iteration [187/501] Loss: 0.2308\n",
      "Epoch [2/10], iteration [188/501] Loss: 0.2846\n",
      "Epoch [2/10], iteration [189/501] Loss: 0.2158\n",
      "Epoch [2/10], iteration [190/501] Loss: 0.2610\n",
      "Epoch [2/10], iteration [191/501] Loss: 0.2565\n",
      "Epoch [2/10], iteration [192/501] Loss: 0.2358\n",
      "Epoch [2/10], iteration [193/501] Loss: 0.2737\n",
      "Epoch [2/10], iteration [194/501] Loss: 0.2617\n",
      "Epoch [2/10], iteration [195/501] Loss: 0.2847\n",
      "Epoch [2/10], iteration [196/501] Loss: 0.2010\n",
      "Epoch [2/10], iteration [197/501] Loss: 0.2258\n",
      "Epoch [2/10], iteration [198/501] Loss: 0.2205\n",
      "Epoch [2/10], iteration [199/501] Loss: 0.2595\n",
      "Epoch [2/10], iteration [200/501] Loss: 0.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], iteration [201/501] Loss: 0.2390\n",
      "Epoch [2/10], iteration [202/501] Loss: 0.2458\n",
      "Epoch [2/10], iteration [203/501] Loss: 0.2279\n",
      "Epoch [2/10], iteration [204/501] Loss: 0.2235\n",
      "Epoch [2/10], iteration [205/501] Loss: 0.2028\n",
      "Epoch [2/10], iteration [206/501] Loss: 0.2497\n",
      "Epoch [2/10], iteration [207/501] Loss: 0.2627\n",
      "Epoch [2/10], iteration [208/501] Loss: 0.2202\n",
      "Epoch [2/10], iteration [209/501] Loss: 0.2285\n",
      "Epoch [2/10], iteration [210/501] Loss: 0.2302\n",
      "Epoch [2/10], iteration [211/501] Loss: 0.2688\n",
      "Epoch [2/10], iteration [212/501] Loss: 0.2626\n",
      "Epoch [2/10], iteration [213/501] Loss: 0.2568\n",
      "Epoch [2/10], iteration [214/501] Loss: 0.2636\n",
      "Epoch [2/10], iteration [215/501] Loss: 0.2179\n",
      "Epoch [2/10], iteration [216/501] Loss: 0.2214\n",
      "Epoch [2/10], iteration [217/501] Loss: 0.2194\n",
      "Epoch [2/10], iteration [218/501] Loss: 0.2605\n",
      "Epoch [2/10], iteration [219/501] Loss: 0.2255\n",
      "Epoch [2/10], iteration [220/501] Loss: 0.2282\n",
      "Epoch [2/10], iteration [221/501] Loss: 0.1948\n",
      "Epoch [2/10], iteration [222/501] Loss: 0.2024\n",
      "Epoch [2/10], iteration [223/501] Loss: 0.2025\n",
      "Epoch [2/10], iteration [224/501] Loss: 0.2154\n",
      "Epoch [2/10], iteration [225/501] Loss: 0.2030\n",
      "Epoch [2/10], iteration [226/501] Loss: 0.2254\n",
      "Epoch [2/10], iteration [227/501] Loss: 0.2478\n",
      "Epoch [2/10], iteration [228/501] Loss: 0.2349\n",
      "Epoch [2/10], iteration [229/501] Loss: 0.2018\n",
      "Epoch [2/10], iteration [230/501] Loss: 0.1739\n",
      "Epoch [2/10], iteration [231/501] Loss: 0.1935\n",
      "Epoch [2/10], iteration [232/501] Loss: 0.2504\n",
      "Epoch [2/10], iteration [233/501] Loss: 0.2154\n",
      "Epoch [2/10], iteration [234/501] Loss: 0.1914\n",
      "Epoch [2/10], iteration [235/501] Loss: 0.2161\n",
      "Epoch [2/10], iteration [236/501] Loss: 0.1994\n",
      "Epoch [2/10], iteration [237/501] Loss: 0.2345\n",
      "Epoch [2/10], iteration [238/501] Loss: 0.2550\n",
      "Epoch [2/10], iteration [239/501] Loss: 0.2198\n",
      "Epoch [2/10], iteration [240/501] Loss: 0.2054\n",
      "Epoch [2/10], iteration [241/501] Loss: 0.1732\n",
      "Epoch [2/10], iteration [242/501] Loss: 0.2223\n",
      "Epoch [2/10], iteration [243/501] Loss: 0.2024\n",
      "Epoch [2/10], iteration [244/501] Loss: 0.2374\n",
      "Epoch [2/10], iteration [245/501] Loss: 0.2112\n",
      "Epoch [2/10], iteration [246/501] Loss: 0.2269\n",
      "Epoch [2/10], iteration [247/501] Loss: 0.1593\n",
      "Epoch [2/10], iteration [248/501] Loss: 0.2574\n",
      "Epoch [2/10], iteration [249/501] Loss: 0.2291\n",
      "Epoch [2/10], iteration [250/501] Loss: 0.2148\n",
      "Epoch [2/10], iteration [251/501] Loss: 0.1662\n",
      "Epoch [2/10], iteration [252/501] Loss: 0.1714\n",
      "Epoch [2/10], iteration [253/501] Loss: 0.2260\n",
      "Epoch [2/10], iteration [254/501] Loss: 0.1922\n",
      "Epoch [2/10], iteration [255/501] Loss: 0.2169\n",
      "Epoch [2/10], iteration [256/501] Loss: 0.1889\n",
      "Epoch [2/10], iteration [257/501] Loss: 0.1920\n",
      "Epoch [2/10], iteration [258/501] Loss: 0.1901\n",
      "Epoch [2/10], iteration [259/501] Loss: 0.1728\n",
      "Epoch [2/10], iteration [260/501] Loss: 0.2392\n",
      "Epoch [2/10], iteration [261/501] Loss: 0.1998\n",
      "Epoch [2/10], iteration [262/501] Loss: 0.1974\n",
      "Epoch [2/10], iteration [263/501] Loss: 0.2512\n",
      "Epoch [2/10], iteration [264/501] Loss: 0.1771\n",
      "Epoch [2/10], iteration [265/501] Loss: 0.2390\n",
      "Epoch [2/10], iteration [266/501] Loss: 0.1738\n",
      "Epoch [2/10], iteration [267/501] Loss: 0.1780\n",
      "Epoch [2/10], iteration [268/501] Loss: 0.1793\n",
      "Epoch [2/10], iteration [269/501] Loss: 0.1720\n",
      "Epoch [2/10], iteration [270/501] Loss: 0.1911\n",
      "Epoch [2/10], iteration [271/501] Loss: 0.1943\n",
      "Epoch [2/10], iteration [272/501] Loss: 0.1581\n",
      "Epoch [2/10], iteration [273/501] Loss: 0.1890\n",
      "Epoch [2/10], iteration [274/501] Loss: 0.1801\n",
      "Epoch [2/10], iteration [275/501] Loss: 0.2025\n",
      "Epoch [2/10], iteration [276/501] Loss: 0.1672\n",
      "Epoch [2/10], iteration [277/501] Loss: 0.1973\n",
      "Epoch [2/10], iteration [278/501] Loss: 0.1855\n",
      "Epoch [2/10], iteration [279/501] Loss: 0.2461\n",
      "Epoch [2/10], iteration [280/501] Loss: 0.1701\n",
      "Epoch [2/10], iteration [281/501] Loss: 0.1854\n",
      "Epoch [2/10], iteration [282/501] Loss: 0.1801\n",
      "Epoch [2/10], iteration [283/501] Loss: 0.2135\n",
      "Epoch [2/10], iteration [284/501] Loss: 0.1965\n",
      "Epoch [2/10], iteration [285/501] Loss: 0.1857\n",
      "Epoch [2/10], iteration [286/501] Loss: 0.1747\n",
      "Epoch [2/10], iteration [287/501] Loss: 0.1507\n",
      "Epoch [2/10], iteration [288/501] Loss: 0.1652\n",
      "Epoch [2/10], iteration [289/501] Loss: 0.1923\n",
      "Epoch [2/10], iteration [290/501] Loss: 0.1556\n",
      "Epoch [2/10], iteration [291/501] Loss: 0.1427\n",
      "Epoch [2/10], iteration [292/501] Loss: 0.2187\n",
      "Epoch [2/10], iteration [293/501] Loss: 0.1582\n",
      "Epoch [2/10], iteration [294/501] Loss: 0.1796\n",
      "Epoch [2/10], iteration [295/501] Loss: 0.1675\n",
      "Epoch [2/10], iteration [296/501] Loss: 0.1605\n",
      "Epoch [2/10], iteration [297/501] Loss: 0.1734\n",
      "Epoch [2/10], iteration [298/501] Loss: 0.1839\n",
      "Epoch [2/10], iteration [299/501] Loss: 0.1374\n",
      "Epoch [2/10], iteration [300/501] Loss: 0.1968\n",
      "Epoch [2/10], iteration [301/501] Loss: 0.1940\n",
      "Epoch [2/10], iteration [302/501] Loss: 0.1896\n",
      "Epoch [2/10], iteration [303/501] Loss: 0.1979\n",
      "Epoch [2/10], iteration [304/501] Loss: 0.1951\n",
      "Epoch [2/10], iteration [305/501] Loss: 0.2171\n",
      "Epoch [2/10], iteration [306/501] Loss: 0.1546\n",
      "Epoch [2/10], iteration [307/501] Loss: 0.1566\n",
      "Epoch [2/10], iteration [308/501] Loss: 0.1390\n",
      "Epoch [2/10], iteration [309/501] Loss: 0.1488\n",
      "Epoch [2/10], iteration [310/501] Loss: 0.1951\n",
      "Epoch [2/10], iteration [311/501] Loss: 0.1590\n",
      "Epoch [2/10], iteration [312/501] Loss: 0.1812\n",
      "Epoch [2/10], iteration [313/501] Loss: 0.2220\n",
      "Epoch [2/10], iteration [314/501] Loss: 0.1519\n",
      "Epoch [2/10], iteration [315/501] Loss: 0.1784\n",
      "Epoch [2/10], iteration [316/501] Loss: 0.1354\n",
      "Epoch [2/10], iteration [317/501] Loss: 0.2261\n",
      "Epoch [2/10], iteration [318/501] Loss: 0.1693\n",
      "Epoch [2/10], iteration [319/501] Loss: 0.1652\n",
      "Epoch [2/10], iteration [320/501] Loss: 0.1739\n",
      "Epoch [2/10], iteration [321/501] Loss: 0.1943\n",
      "Epoch [2/10], iteration [322/501] Loss: 0.2361\n",
      "Epoch [2/10], iteration [323/501] Loss: 0.1738\n",
      "Epoch [2/10], iteration [324/501] Loss: 0.1842\n",
      "Epoch [2/10], iteration [325/501] Loss: 0.2069\n",
      "Epoch [2/10], iteration [326/501] Loss: 0.1840\n",
      "Epoch [2/10], iteration [327/501] Loss: 0.1858\n",
      "Epoch [2/10], iteration [328/501] Loss: 0.1918\n",
      "Epoch [2/10], iteration [329/501] Loss: 0.1455\n",
      "Epoch [2/10], iteration [330/501] Loss: 0.1585\n",
      "Epoch [2/10], iteration [331/501] Loss: 0.2464\n",
      "Epoch [2/10], iteration [332/501] Loss: 0.1545\n",
      "Epoch [2/10], iteration [333/501] Loss: 0.1821\n",
      "Epoch [2/10], iteration [334/501] Loss: 0.1890\n",
      "Epoch [2/10], iteration [335/501] Loss: 0.2385\n",
      "Epoch [2/10], iteration [336/501] Loss: 0.1735\n",
      "Epoch [2/10], iteration [337/501] Loss: 0.1779\n",
      "Epoch [2/10], iteration [338/501] Loss: 0.2439\n",
      "Epoch [2/10], iteration [339/501] Loss: 0.1714\n",
      "Epoch [2/10], iteration [340/501] Loss: 0.2041\n",
      "Epoch [2/10], iteration [341/501] Loss: 0.1885\n",
      "Epoch [2/10], iteration [342/501] Loss: 0.1928\n",
      "Epoch [2/10], iteration [343/501] Loss: 0.2076\n",
      "Epoch [2/10], iteration [344/501] Loss: 0.1445\n",
      "Epoch [2/10], iteration [345/501] Loss: 0.2018\n",
      "Epoch [2/10], iteration [346/501] Loss: 0.2210\n",
      "Epoch [2/10], iteration [347/501] Loss: 0.1809\n",
      "Epoch [2/10], iteration [348/501] Loss: 0.2076\n",
      "Epoch [2/10], iteration [349/501] Loss: 0.2048\n",
      "Epoch [2/10], iteration [350/501] Loss: 0.1764\n",
      "Epoch [2/10], iteration [351/501] Loss: 0.2412\n",
      "Epoch [2/10], iteration [352/501] Loss: 0.1766\n",
      "Epoch [2/10], iteration [353/501] Loss: 0.2348\n",
      "Epoch [2/10], iteration [354/501] Loss: 0.1627\n",
      "Epoch [2/10], iteration [355/501] Loss: 0.1722\n",
      "Epoch [2/10], iteration [356/501] Loss: 0.1889\n",
      "Epoch [2/10], iteration [357/501] Loss: 0.1728\n",
      "Epoch [2/10], iteration [358/501] Loss: 0.1763\n",
      "Epoch [2/10], iteration [359/501] Loss: 0.1812\n",
      "Epoch [2/10], iteration [360/501] Loss: 0.1689\n",
      "Epoch [2/10], iteration [361/501] Loss: 0.2114\n",
      "Epoch [2/10], iteration [362/501] Loss: 0.1726\n",
      "Epoch [2/10], iteration [363/501] Loss: 0.1992\n",
      "Epoch [2/10], iteration [364/501] Loss: 0.1944\n",
      "Epoch [2/10], iteration [365/501] Loss: 0.1267\n",
      "Epoch [2/10], iteration [366/501] Loss: 0.1326\n",
      "Epoch [2/10], iteration [367/501] Loss: 0.1916\n",
      "Epoch [2/10], iteration [368/501] Loss: 0.1912\n",
      "Epoch [2/10], iteration [369/501] Loss: 0.1454\n",
      "Epoch [2/10], iteration [370/501] Loss: 0.1705\n",
      "Epoch [2/10], iteration [371/501] Loss: 0.1485\n",
      "Epoch [2/10], iteration [372/501] Loss: 0.1522\n",
      "Epoch [2/10], iteration [373/501] Loss: 0.2027\n",
      "Epoch [2/10], iteration [374/501] Loss: 0.2167\n",
      "Epoch [2/10], iteration [375/501] Loss: 0.2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], iteration [376/501] Loss: 0.1659\n",
      "Epoch [2/10], iteration [377/501] Loss: 0.2019\n",
      "Epoch [2/10], iteration [378/501] Loss: 0.1672\n",
      "Epoch [2/10], iteration [379/501] Loss: 0.1778\n",
      "Epoch [2/10], iteration [380/501] Loss: 0.1653\n",
      "Epoch [2/10], iteration [381/501] Loss: 0.1814\n",
      "Epoch [2/10], iteration [382/501] Loss: 0.2004\n",
      "Epoch [2/10], iteration [383/501] Loss: 0.1401\n",
      "Epoch [2/10], iteration [384/501] Loss: 0.1357\n",
      "Epoch [2/10], iteration [385/501] Loss: 0.1768\n",
      "Epoch [2/10], iteration [386/501] Loss: 0.1824\n",
      "Epoch [2/10], iteration [387/501] Loss: 0.2125\n",
      "Epoch [2/10], iteration [388/501] Loss: 0.1279\n",
      "Epoch [2/10], iteration [389/501] Loss: 0.1459\n",
      "Epoch [2/10], iteration [390/501] Loss: 0.1970\n",
      "Epoch [2/10], iteration [391/501] Loss: 0.1633\n",
      "Epoch [2/10], iteration [392/501] Loss: 0.1695\n",
      "Epoch [2/10], iteration [393/501] Loss: 0.1902\n",
      "Epoch [2/10], iteration [394/501] Loss: 0.1805\n",
      "Epoch [2/10], iteration [395/501] Loss: 0.2025\n",
      "Epoch [2/10], iteration [396/501] Loss: 0.1585\n",
      "Epoch [2/10], iteration [397/501] Loss: 0.1296\n",
      "Epoch [2/10], iteration [398/501] Loss: 0.1942\n",
      "Epoch [2/10], iteration [399/501] Loss: 0.1345\n",
      "Epoch [2/10], iteration [400/501] Loss: 0.1838\n",
      "Epoch [2/10], iteration [401/501] Loss: 0.1557\n",
      "Epoch [2/10], iteration [402/501] Loss: 0.1547\n",
      "Epoch [2/10], iteration [403/501] Loss: 0.1447\n",
      "Epoch [2/10], iteration [404/501] Loss: 0.1114\n",
      "Epoch [2/10], iteration [405/501] Loss: 0.1693\n",
      "Epoch [2/10], iteration [406/501] Loss: 0.1519\n",
      "Epoch [2/10], iteration [407/501] Loss: 0.1798\n",
      "Epoch [2/10], iteration [408/501] Loss: 0.1516\n",
      "Epoch [2/10], iteration [409/501] Loss: 0.1546\n",
      "Epoch [2/10], iteration [410/501] Loss: 0.1281\n",
      "Epoch [2/10], iteration [411/501] Loss: 0.1574\n",
      "Epoch [2/10], iteration [412/501] Loss: 0.2195\n",
      "Epoch [2/10], iteration [413/501] Loss: 0.1272\n",
      "Epoch [2/10], iteration [414/501] Loss: 0.1976\n",
      "Epoch [2/10], iteration [415/501] Loss: 0.1916\n",
      "Epoch [2/10], iteration [416/501] Loss: 0.1749\n",
      "Epoch [2/10], iteration [417/501] Loss: 0.1359\n",
      "Epoch [2/10], iteration [418/501] Loss: 0.1465\n",
      "Epoch [2/10], iteration [419/501] Loss: 0.1438\n",
      "Epoch [2/10], iteration [420/501] Loss: 0.1313\n",
      "Epoch [2/10], iteration [421/501] Loss: 0.1484\n",
      "Epoch [2/10], iteration [422/501] Loss: 0.1692\n",
      "Epoch [2/10], iteration [423/501] Loss: 0.1466\n",
      "Epoch [2/10], iteration [424/501] Loss: 0.1274\n",
      "Epoch [2/10], iteration [425/501] Loss: 0.1811\n",
      "Epoch [2/10], iteration [426/501] Loss: 0.1298\n",
      "Epoch [2/10], iteration [427/501] Loss: 0.1600\n",
      "Epoch [2/10], iteration [428/501] Loss: 0.1285\n",
      "Epoch [2/10], iteration [429/501] Loss: 0.1382\n",
      "Epoch [2/10], iteration [430/501] Loss: 0.1792\n",
      "Epoch [2/10], iteration [431/501] Loss: 0.1555\n",
      "Epoch [2/10], iteration [432/501] Loss: 0.1331\n",
      "Epoch [2/10], iteration [433/501] Loss: 0.1803\n",
      "Epoch [2/10], iteration [434/501] Loss: 0.1676\n",
      "Epoch [2/10], iteration [435/501] Loss: 0.1373\n",
      "Epoch [2/10], iteration [436/501] Loss: 0.1533\n",
      "Epoch [2/10], iteration [437/501] Loss: 0.1270\n",
      "Epoch [2/10], iteration [438/501] Loss: 0.1053\n",
      "Epoch [2/10], iteration [439/501] Loss: 0.1132\n",
      "Epoch [2/10], iteration [440/501] Loss: 0.1217\n",
      "Epoch [2/10], iteration [441/501] Loss: 0.1313\n",
      "Epoch [2/10], iteration [442/501] Loss: 0.1421\n",
      "Epoch [2/10], iteration [443/501] Loss: 0.1381\n",
      "Epoch [2/10], iteration [444/501] Loss: 0.1248\n",
      "Epoch [2/10], iteration [445/501] Loss: 0.1748\n",
      "Epoch [2/10], iteration [446/501] Loss: 0.1027\n",
      "Epoch [2/10], iteration [447/501] Loss: 0.1182\n",
      "Epoch [2/10], iteration [448/501] Loss: 0.1511\n",
      "Epoch [2/10], iteration [449/501] Loss: 0.1581\n",
      "Epoch [2/10], iteration [450/501] Loss: 0.1390\n",
      "Epoch [2/10], iteration [451/501] Loss: 0.1258\n",
      "Epoch [2/10], iteration [452/501] Loss: 0.1435\n",
      "Epoch [2/10], iteration [453/501] Loss: 0.1324\n",
      "Epoch [2/10], iteration [454/501] Loss: 0.1636\n",
      "Epoch [2/10], iteration [455/501] Loss: 0.1126\n",
      "Epoch [2/10], iteration [456/501] Loss: 0.1199\n",
      "Epoch [2/10], iteration [457/501] Loss: 0.1236\n",
      "Epoch [2/10], iteration [458/501] Loss: 0.1010\n",
      "Epoch [2/10], iteration [459/501] Loss: 0.1216\n",
      "Epoch [2/10], iteration [460/501] Loss: 0.0890\n",
      "Epoch [2/10], iteration [461/501] Loss: 0.1452\n",
      "Epoch [2/10], iteration [462/501] Loss: 0.0985\n",
      "Epoch [2/10], iteration [463/501] Loss: 0.1442\n",
      "Epoch [2/10], iteration [464/501] Loss: 0.1183\n",
      "Epoch [2/10], iteration [465/501] Loss: 0.1478\n",
      "Epoch [2/10], iteration [466/501] Loss: 0.1352\n",
      "Epoch [2/10], iteration [467/501] Loss: 0.1263\n",
      "Epoch [2/10], iteration [468/501] Loss: 0.1553\n",
      "Epoch [2/10], iteration [469/501] Loss: 0.1552\n",
      "Epoch [2/10], iteration [470/501] Loss: 0.1396\n",
      "Epoch [2/10], iteration [471/501] Loss: 0.1562\n",
      "Epoch [2/10], iteration [472/501] Loss: 0.0865\n",
      "Epoch [2/10], iteration [473/501] Loss: 0.1677\n",
      "Epoch [2/10], iteration [474/501] Loss: 0.1989\n",
      "Epoch [2/10], iteration [475/501] Loss: 0.0904\n",
      "Epoch [2/10], iteration [476/501] Loss: 0.1604\n",
      "Epoch [2/10], iteration [477/501] Loss: 0.1455\n",
      "Epoch [2/10], iteration [478/501] Loss: 0.1318\n",
      "Epoch [2/10], iteration [479/501] Loss: 0.1097\n",
      "Epoch [2/10], iteration [480/501] Loss: 0.1093\n",
      "Epoch [2/10], iteration [481/501] Loss: 0.1621\n",
      "Epoch [2/10], iteration [482/501] Loss: 0.1261\n",
      "Epoch [2/10], iteration [483/501] Loss: 0.1594\n",
      "Epoch [2/10], iteration [484/501] Loss: 0.1534\n",
      "Epoch [2/10], iteration [485/501] Loss: 0.1093\n",
      "Epoch [2/10], iteration [486/501] Loss: 0.1068\n",
      "Epoch [2/10], iteration [487/501] Loss: 0.1628\n",
      "Epoch [2/10], iteration [488/501] Loss: 0.1007\n",
      "Epoch [2/10], iteration [489/501] Loss: 0.1440\n",
      "Epoch [2/10], iteration [490/501] Loss: 0.1577\n",
      "Epoch [2/10], iteration [491/501] Loss: 0.1228\n",
      "Epoch [2/10], iteration [492/501] Loss: 0.1038\n",
      "Epoch [2/10], iteration [493/501] Loss: 0.1552\n",
      "Epoch [2/10], iteration [494/501] Loss: 0.1234\n",
      "Epoch [2/10], iteration [495/501] Loss: 0.1437\n",
      "Epoch [2/10], iteration [496/501] Loss: 0.1623\n",
      "Epoch [2/10], iteration [497/501] Loss: 0.1017\n",
      "Epoch [2/10], iteration [498/501] Loss: 0.0891\n",
      "Epoch [2/10], iteration [499/501] Loss: 0.1626\n",
      "Epoch [2/10], iteration [500/501] Loss: 0.1111\n",
      "Epoch [2/10], iteration [501/501] Loss: 0.0630\n",
      "Epoch [2/10], Test Accuracy of the model on the 2350 test images: 98.80851063829788 %\n",
      "Epoch [3/10], iteration [1/501] Loss: 0.1182\n",
      "Epoch [3/10], iteration [2/501] Loss: 0.1001\n",
      "Epoch [3/10], iteration [3/501] Loss: 0.1186\n",
      "Epoch [3/10], iteration [4/501] Loss: 0.1528\n",
      "Epoch [3/10], iteration [5/501] Loss: 0.2064\n",
      "Epoch [3/10], iteration [6/501] Loss: 0.0966\n",
      "Epoch [3/10], iteration [7/501] Loss: 0.1169\n",
      "Epoch [3/10], iteration [8/501] Loss: 0.1213\n",
      "Epoch [3/10], iteration [9/501] Loss: 0.0840\n",
      "Epoch [3/10], iteration [10/501] Loss: 0.0936\n",
      "Epoch [3/10], iteration [11/501] Loss: 0.0830\n",
      "Epoch [3/10], iteration [12/501] Loss: 0.0971\n",
      "Epoch [3/10], iteration [13/501] Loss: 0.0689\n",
      "Epoch [3/10], iteration [14/501] Loss: 0.0972\n",
      "Epoch [3/10], iteration [15/501] Loss: 0.0749\n",
      "Epoch [3/10], iteration [16/501] Loss: 0.0960\n",
      "Epoch [3/10], iteration [17/501] Loss: 0.1161\n",
      "Epoch [3/10], iteration [18/501] Loss: 0.1090\n",
      "Epoch [3/10], iteration [19/501] Loss: 0.1324\n",
      "Epoch [3/10], iteration [20/501] Loss: 0.0656\n",
      "Epoch [3/10], iteration [21/501] Loss: 0.1193\n",
      "Epoch [3/10], iteration [22/501] Loss: 0.0965\n",
      "Epoch [3/10], iteration [23/501] Loss: 0.0777\n",
      "Epoch [3/10], iteration [24/501] Loss: 0.0950\n",
      "Epoch [3/10], iteration [25/501] Loss: 0.0855\n",
      "Epoch [3/10], iteration [26/501] Loss: 0.1039\n",
      "Epoch [3/10], iteration [27/501] Loss: 0.0893\n",
      "Epoch [3/10], iteration [28/501] Loss: 0.0584\n",
      "Epoch [3/10], iteration [29/501] Loss: 0.1067\n",
      "Epoch [3/10], iteration [30/501] Loss: 0.0976\n",
      "Epoch [3/10], iteration [31/501] Loss: 0.0743\n",
      "Epoch [3/10], iteration [32/501] Loss: 0.0618\n",
      "Epoch [3/10], iteration [33/501] Loss: 0.0789\n",
      "Epoch [3/10], iteration [34/501] Loss: 0.0970\n",
      "Epoch [3/10], iteration [35/501] Loss: 0.0508\n",
      "Epoch [3/10], iteration [36/501] Loss: 0.0771\n",
      "Epoch [3/10], iteration [37/501] Loss: 0.0931\n",
      "Epoch [3/10], iteration [38/501] Loss: 0.1041\n",
      "Epoch [3/10], iteration [39/501] Loss: 0.0984\n",
      "Epoch [3/10], iteration [40/501] Loss: 0.1084\n",
      "Epoch [3/10], iteration [41/501] Loss: 0.0803\n",
      "Epoch [3/10], iteration [42/501] Loss: 0.0718\n",
      "Epoch [3/10], iteration [43/501] Loss: 0.0569\n",
      "Epoch [3/10], iteration [44/501] Loss: 0.1097\n",
      "Epoch [3/10], iteration [45/501] Loss: 0.0649\n",
      "Epoch [3/10], iteration [46/501] Loss: 0.0893\n",
      "Epoch [3/10], iteration [47/501] Loss: 0.0765\n",
      "Epoch [3/10], iteration [48/501] Loss: 0.0770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], iteration [49/501] Loss: 0.0747\n",
      "Epoch [3/10], iteration [50/501] Loss: 0.0661\n",
      "Epoch [3/10], iteration [51/501] Loss: 0.0798\n",
      "Epoch [3/10], iteration [52/501] Loss: 0.1335\n",
      "Epoch [3/10], iteration [53/501] Loss: 0.0694\n",
      "Epoch [3/10], iteration [54/501] Loss: 0.0816\n",
      "Epoch [3/10], iteration [55/501] Loss: 0.1013\n",
      "Epoch [3/10], iteration [56/501] Loss: 0.0905\n",
      "Epoch [3/10], iteration [57/501] Loss: 0.0862\n",
      "Epoch [3/10], iteration [58/501] Loss: 0.0617\n",
      "Epoch [3/10], iteration [59/501] Loss: 0.0881\n",
      "Epoch [3/10], iteration [60/501] Loss: 0.0624\n",
      "Epoch [3/10], iteration [61/501] Loss: 0.1016\n",
      "Epoch [3/10], iteration [62/501] Loss: 0.0660\n",
      "Epoch [3/10], iteration [63/501] Loss: 0.0758\n",
      "Epoch [3/10], iteration [64/501] Loss: 0.1046\n",
      "Epoch [3/10], iteration [65/501] Loss: 0.0810\n",
      "Epoch [3/10], iteration [66/501] Loss: 0.0668\n",
      "Epoch [3/10], iteration [67/501] Loss: 0.0648\n",
      "Epoch [3/10], iteration [68/501] Loss: 0.0841\n",
      "Epoch [3/10], iteration [69/501] Loss: 0.1016\n",
      "Epoch [3/10], iteration [70/501] Loss: 0.0596\n",
      "Epoch [3/10], iteration [71/501] Loss: 0.0649\n",
      "Epoch [3/10], iteration [72/501] Loss: 0.0951\n",
      "Epoch [3/10], iteration [73/501] Loss: 0.0983\n",
      "Epoch [3/10], iteration [74/501] Loss: 0.1133\n",
      "Epoch [3/10], iteration [75/501] Loss: 0.0402\n",
      "Epoch [3/10], iteration [76/501] Loss: 0.0838\n",
      "Epoch [3/10], iteration [77/501] Loss: 0.0845\n",
      "Epoch [3/10], iteration [78/501] Loss: 0.0719\n",
      "Epoch [3/10], iteration [79/501] Loss: 0.0735\n",
      "Epoch [3/10], iteration [80/501] Loss: 0.0911\n",
      "Epoch [3/10], iteration [81/501] Loss: 0.0867\n",
      "Epoch [3/10], iteration [82/501] Loss: 0.0722\n",
      "Epoch [3/10], iteration [83/501] Loss: 0.0818\n",
      "Epoch [3/10], iteration [84/501] Loss: 0.0846\n",
      "Epoch [3/10], iteration [85/501] Loss: 0.0706\n",
      "Epoch [3/10], iteration [86/501] Loss: 0.1009\n",
      "Epoch [3/10], iteration [87/501] Loss: 0.0828\n",
      "Epoch [3/10], iteration [88/501] Loss: 0.0771\n",
      "Epoch [3/10], iteration [89/501] Loss: 0.1181\n",
      "Epoch [3/10], iteration [90/501] Loss: 0.1100\n",
      "Epoch [3/10], iteration [91/501] Loss: 0.1005\n",
      "Epoch [3/10], iteration [92/501] Loss: 0.0727\n",
      "Epoch [3/10], iteration [93/501] Loss: 0.0788\n",
      "Epoch [3/10], iteration [94/501] Loss: 0.0577\n",
      "Epoch [3/10], iteration [95/501] Loss: 0.0966\n",
      "Epoch [3/10], iteration [96/501] Loss: 0.0815\n",
      "Epoch [3/10], iteration [97/501] Loss: 0.0425\n",
      "Epoch [3/10], iteration [98/501] Loss: 0.0705\n",
      "Epoch [3/10], iteration [99/501] Loss: 0.0675\n",
      "Epoch [3/10], iteration [100/501] Loss: 0.0821\n",
      "Epoch [3/10], iteration [101/501] Loss: 0.0822\n",
      "Epoch [3/10], iteration [102/501] Loss: 0.0883\n",
      "Epoch [3/10], iteration [103/501] Loss: 0.0695\n",
      "Epoch [3/10], iteration [104/501] Loss: 0.0947\n",
      "Epoch [3/10], iteration [105/501] Loss: 0.0977\n",
      "Epoch [3/10], iteration [106/501] Loss: 0.0654\n",
      "Epoch [3/10], iteration [107/501] Loss: 0.0748\n",
      "Epoch [3/10], iteration [108/501] Loss: 0.0624\n",
      "Epoch [3/10], iteration [109/501] Loss: 0.0824\n",
      "Epoch [3/10], iteration [110/501] Loss: 0.0855\n",
      "Epoch [3/10], iteration [111/501] Loss: 0.1237\n",
      "Epoch [3/10], iteration [112/501] Loss: 0.0947\n",
      "Epoch [3/10], iteration [113/501] Loss: 0.0886\n",
      "Epoch [3/10], iteration [114/501] Loss: 0.0504\n",
      "Epoch [3/10], iteration [115/501] Loss: 0.0653\n",
      "Epoch [3/10], iteration [116/501] Loss: 0.0681\n",
      "Epoch [3/10], iteration [117/501] Loss: 0.0662\n",
      "Epoch [3/10], iteration [118/501] Loss: 0.0663\n",
      "Epoch [3/10], iteration [119/501] Loss: 0.1125\n",
      "Epoch [3/10], iteration [120/501] Loss: 0.0784\n",
      "Epoch [3/10], iteration [121/501] Loss: 0.0792\n",
      "Epoch [3/10], iteration [122/501] Loss: 0.0690\n",
      "Epoch [3/10], iteration [123/501] Loss: 0.1073\n",
      "Epoch [3/10], iteration [124/501] Loss: 0.1063\n",
      "Epoch [3/10], iteration [125/501] Loss: 0.1016\n",
      "Epoch [3/10], iteration [126/501] Loss: 0.1105\n",
      "Epoch [3/10], iteration [127/501] Loss: 0.0581\n",
      "Epoch [3/10], iteration [128/501] Loss: 0.0864\n",
      "Epoch [3/10], iteration [129/501] Loss: 0.1112\n",
      "Epoch [3/10], iteration [130/501] Loss: 0.0703\n",
      "Epoch [3/10], iteration [131/501] Loss: 0.0585\n",
      "Epoch [3/10], iteration [132/501] Loss: 0.0763\n",
      "Epoch [3/10], iteration [133/501] Loss: 0.0641\n",
      "Epoch [3/10], iteration [134/501] Loss: 0.0845\n",
      "Epoch [3/10], iteration [135/501] Loss: 0.0793\n",
      "Epoch [3/10], iteration [136/501] Loss: 0.1162\n",
      "Epoch [3/10], iteration [137/501] Loss: 0.0695\n",
      "Epoch [3/10], iteration [138/501] Loss: 0.0805\n",
      "Epoch [3/10], iteration [139/501] Loss: 0.0795\n",
      "Epoch [3/10], iteration [140/501] Loss: 0.0724\n",
      "Epoch [3/10], iteration [141/501] Loss: 0.0820\n",
      "Epoch [3/10], iteration [142/501] Loss: 0.1175\n",
      "Epoch [3/10], iteration [143/501] Loss: 0.0654\n",
      "Epoch [3/10], iteration [144/501] Loss: 0.1134\n",
      "Epoch [3/10], iteration [145/501] Loss: 0.1142\n",
      "Epoch [3/10], iteration [146/501] Loss: 0.0744\n",
      "Epoch [3/10], iteration [147/501] Loss: 0.0799\n",
      "Epoch [3/10], iteration [148/501] Loss: 0.0917\n",
      "Epoch [3/10], iteration [149/501] Loss: 0.0680\n",
      "Epoch [3/10], iteration [150/501] Loss: 0.0792\n",
      "Epoch [3/10], iteration [151/501] Loss: 0.1096\n",
      "Epoch [3/10], iteration [152/501] Loss: 0.0967\n",
      "Epoch [3/10], iteration [153/501] Loss: 0.0869\n",
      "Epoch [3/10], iteration [154/501] Loss: 0.1081\n",
      "Epoch [3/10], iteration [155/501] Loss: 0.0979\n",
      "Epoch [3/10], iteration [156/501] Loss: 0.0629\n",
      "Epoch [3/10], iteration [157/501] Loss: 0.0838\n",
      "Epoch [3/10], iteration [158/501] Loss: 0.0697\n",
      "Epoch [3/10], iteration [159/501] Loss: 0.0626\n",
      "Epoch [3/10], iteration [160/501] Loss: 0.0920\n",
      "Epoch [3/10], iteration [161/501] Loss: 0.1055\n",
      "Epoch [3/10], iteration [162/501] Loss: 0.0868\n",
      "Epoch [3/10], iteration [163/501] Loss: 0.1047\n",
      "Epoch [3/10], iteration [164/501] Loss: 0.0889\n",
      "Epoch [3/10], iteration [165/501] Loss: 0.0892\n",
      "Epoch [3/10], iteration [166/501] Loss: 0.0897\n",
      "Epoch [3/10], iteration [167/501] Loss: 0.0824\n",
      "Epoch [3/10], iteration [168/501] Loss: 0.0914\n",
      "Epoch [3/10], iteration [169/501] Loss: 0.0760\n",
      "Epoch [3/10], iteration [170/501] Loss: 0.0602\n",
      "Epoch [3/10], iteration [171/501] Loss: 0.0631\n",
      "Epoch [3/10], iteration [172/501] Loss: 0.0898\n",
      "Epoch [3/10], iteration [173/501] Loss: 0.0888\n",
      "Epoch [3/10], iteration [174/501] Loss: 0.1224\n",
      "Epoch [3/10], iteration [175/501] Loss: 0.0873\n",
      "Epoch [3/10], iteration [176/501] Loss: 0.0942\n",
      "Epoch [3/10], iteration [177/501] Loss: 0.1051\n",
      "Epoch [3/10], iteration [178/501] Loss: 0.0989\n",
      "Epoch [3/10], iteration [179/501] Loss: 0.1118\n",
      "Epoch [3/10], iteration [180/501] Loss: 0.0822\n",
      "Epoch [3/10], iteration [181/501] Loss: 0.1321\n",
      "Epoch [3/10], iteration [182/501] Loss: 0.0669\n",
      "Epoch [3/10], iteration [183/501] Loss: 0.1452\n",
      "Epoch [3/10], iteration [184/501] Loss: 0.0811\n",
      "Epoch [3/10], iteration [185/501] Loss: 0.1320\n",
      "Epoch [3/10], iteration [186/501] Loss: 0.1300\n",
      "Epoch [3/10], iteration [187/501] Loss: 0.0750\n",
      "Epoch [3/10], iteration [188/501] Loss: 0.0645\n",
      "Epoch [3/10], iteration [189/501] Loss: 0.1199\n",
      "Epoch [3/10], iteration [190/501] Loss: 0.0995\n",
      "Epoch [3/10], iteration [191/501] Loss: 0.1109\n",
      "Epoch [3/10], iteration [192/501] Loss: 0.1230\n",
      "Epoch [3/10], iteration [193/501] Loss: 0.0604\n",
      "Epoch [3/10], iteration [194/501] Loss: 0.0893\n",
      "Epoch [3/10], iteration [195/501] Loss: 0.1028\n",
      "Epoch [3/10], iteration [196/501] Loss: 0.1212\n",
      "Epoch [3/10], iteration [197/501] Loss: 0.0843\n",
      "Epoch [3/10], iteration [198/501] Loss: 0.0881\n",
      "Epoch [3/10], iteration [199/501] Loss: 0.0796\n",
      "Epoch [3/10], iteration [200/501] Loss: 0.0861\n",
      "Epoch [3/10], iteration [201/501] Loss: 0.0816\n",
      "Epoch [3/10], iteration [202/501] Loss: 0.0961\n",
      "Epoch [3/10], iteration [203/501] Loss: 0.0948\n",
      "Epoch [3/10], iteration [204/501] Loss: 0.0818\n",
      "Epoch [3/10], iteration [205/501] Loss: 0.0775\n",
      "Epoch [3/10], iteration [206/501] Loss: 0.0971\n",
      "Epoch [3/10], iteration [207/501] Loss: 0.1059\n",
      "Epoch [3/10], iteration [208/501] Loss: 0.0764\n",
      "Epoch [3/10], iteration [209/501] Loss: 0.0912\n",
      "Epoch [3/10], iteration [210/501] Loss: 0.0826\n",
      "Epoch [3/10], iteration [211/501] Loss: 0.0930\n",
      "Epoch [3/10], iteration [212/501] Loss: 0.0948\n",
      "Epoch [3/10], iteration [213/501] Loss: 0.1129\n",
      "Epoch [3/10], iteration [214/501] Loss: 0.0939\n",
      "Epoch [3/10], iteration [215/501] Loss: 0.1391\n",
      "Epoch [3/10], iteration [216/501] Loss: 0.0665\n",
      "Epoch [3/10], iteration [217/501] Loss: 0.0933\n",
      "Epoch [3/10], iteration [218/501] Loss: 0.1085\n",
      "Epoch [3/10], iteration [219/501] Loss: 0.0984\n",
      "Epoch [3/10], iteration [220/501] Loss: 0.1044\n",
      "Epoch [3/10], iteration [221/501] Loss: 0.0831\n",
      "Epoch [3/10], iteration [222/501] Loss: 0.1275\n",
      "Epoch [3/10], iteration [223/501] Loss: 0.1108\n",
      "Epoch [3/10], iteration [224/501] Loss: 0.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], iteration [225/501] Loss: 0.0999\n",
      "Epoch [3/10], iteration [226/501] Loss: 0.1049\n",
      "Epoch [3/10], iteration [227/501] Loss: 0.1017\n",
      "Epoch [3/10], iteration [228/501] Loss: 0.0994\n",
      "Epoch [3/10], iteration [229/501] Loss: 0.1196\n",
      "Epoch [3/10], iteration [230/501] Loss: 0.0999\n",
      "Epoch [3/10], iteration [231/501] Loss: 0.0671\n",
      "Epoch [3/10], iteration [232/501] Loss: 0.1379\n",
      "Epoch [3/10], iteration [233/501] Loss: 0.0717\n",
      "Epoch [3/10], iteration [234/501] Loss: 0.1125\n",
      "Epoch [3/10], iteration [235/501] Loss: 0.0720\n",
      "Epoch [3/10], iteration [236/501] Loss: 0.0750\n",
      "Epoch [3/10], iteration [237/501] Loss: 0.1007\n",
      "Epoch [3/10], iteration [238/501] Loss: 0.1032\n",
      "Epoch [3/10], iteration [239/501] Loss: 0.0649\n",
      "Epoch [3/10], iteration [240/501] Loss: 0.0751\n",
      "Epoch [3/10], iteration [241/501] Loss: 0.1319\n",
      "Epoch [3/10], iteration [242/501] Loss: 0.1014\n",
      "Epoch [3/10], iteration [243/501] Loss: 0.0949\n",
      "Epoch [3/10], iteration [244/501] Loss: 0.0926\n",
      "Epoch [3/10], iteration [245/501] Loss: 0.0631\n",
      "Epoch [3/10], iteration [246/501] Loss: 0.1266\n",
      "Epoch [3/10], iteration [247/501] Loss: 0.0767\n",
      "Epoch [3/10], iteration [248/501] Loss: 0.0789\n",
      "Epoch [3/10], iteration [249/501] Loss: 0.0999\n",
      "Epoch [3/10], iteration [250/501] Loss: 0.0969\n",
      "Epoch [3/10], iteration [251/501] Loss: 0.0748\n",
      "Epoch [3/10], iteration [252/501] Loss: 0.0843\n",
      "Epoch [3/10], iteration [253/501] Loss: 0.1027\n",
      "Epoch [3/10], iteration [254/501] Loss: 0.0913\n",
      "Epoch [3/10], iteration [255/501] Loss: 0.1271\n",
      "Epoch [3/10], iteration [256/501] Loss: 0.0909\n",
      "Epoch [3/10], iteration [257/501] Loss: 0.1331\n",
      "Epoch [3/10], iteration [258/501] Loss: 0.0858\n",
      "Epoch [3/10], iteration [259/501] Loss: 0.0897\n",
      "Epoch [3/10], iteration [260/501] Loss: 0.1194\n",
      "Epoch [3/10], iteration [261/501] Loss: 0.1094\n",
      "Epoch [3/10], iteration [262/501] Loss: 0.1180\n",
      "Epoch [3/10], iteration [263/501] Loss: 0.1441\n",
      "Epoch [3/10], iteration [264/501] Loss: 0.0670\n",
      "Epoch [3/10], iteration [265/501] Loss: 0.0885\n",
      "Epoch [3/10], iteration [266/501] Loss: 0.0678\n",
      "Epoch [3/10], iteration [267/501] Loss: 0.1069\n",
      "Epoch [3/10], iteration [268/501] Loss: 0.1124\n",
      "Epoch [3/10], iteration [269/501] Loss: 0.1338\n",
      "Epoch [3/10], iteration [270/501] Loss: 0.1247\n",
      "Epoch [3/10], iteration [271/501] Loss: 0.0931\n",
      "Epoch [3/10], iteration [272/501] Loss: 0.0949\n",
      "Epoch [3/10], iteration [273/501] Loss: 0.1022\n",
      "Epoch [3/10], iteration [274/501] Loss: 0.1134\n",
      "Epoch [3/10], iteration [275/501] Loss: 0.0748\n",
      "Epoch [3/10], iteration [276/501] Loss: 0.1043\n",
      "Epoch [3/10], iteration [277/501] Loss: 0.1135\n",
      "Epoch [3/10], iteration [278/501] Loss: 0.1353\n",
      "Epoch [3/10], iteration [279/501] Loss: 0.0767\n",
      "Epoch [3/10], iteration [280/501] Loss: 0.0739\n",
      "Epoch [3/10], iteration [281/501] Loss: 0.0880\n",
      "Epoch [3/10], iteration [282/501] Loss: 0.1321\n",
      "Epoch [3/10], iteration [283/501] Loss: 0.0850\n",
      "Epoch [3/10], iteration [284/501] Loss: 0.0756\n",
      "Epoch [3/10], iteration [285/501] Loss: 0.1051\n",
      "Epoch [3/10], iteration [286/501] Loss: 0.1077\n",
      "Epoch [3/10], iteration [287/501] Loss: 0.1251\n",
      "Epoch [3/10], iteration [288/501] Loss: 0.1240\n",
      "Epoch [3/10], iteration [289/501] Loss: 0.1090\n",
      "Epoch [3/10], iteration [290/501] Loss: 0.1483\n",
      "Epoch [3/10], iteration [291/501] Loss: 0.0817\n",
      "Epoch [3/10], iteration [292/501] Loss: 0.1233\n",
      "Epoch [3/10], iteration [293/501] Loss: 0.0866\n",
      "Epoch [3/10], iteration [294/501] Loss: 0.0619\n",
      "Epoch [3/10], iteration [295/501] Loss: 0.0721\n",
      "Epoch [3/10], iteration [296/501] Loss: 0.0829\n",
      "Epoch [3/10], iteration [297/501] Loss: 0.1258\n",
      "Epoch [3/10], iteration [298/501] Loss: 0.0666\n",
      "Epoch [3/10], iteration [299/501] Loss: 0.1105\n",
      "Epoch [3/10], iteration [300/501] Loss: 0.1476\n",
      "Epoch [3/10], iteration [301/501] Loss: 0.0972\n",
      "Epoch [3/10], iteration [302/501] Loss: 0.0901\n",
      "Epoch [3/10], iteration [303/501] Loss: 0.1457\n",
      "Epoch [3/10], iteration [304/501] Loss: 0.0706\n",
      "Epoch [3/10], iteration [305/501] Loss: 0.0832\n",
      "Epoch [3/10], iteration [306/501] Loss: 0.0645\n",
      "Epoch [3/10], iteration [307/501] Loss: 0.0863\n",
      "Epoch [3/10], iteration [308/501] Loss: 0.0735\n",
      "Epoch [3/10], iteration [309/501] Loss: 0.1114\n",
      "Epoch [3/10], iteration [310/501] Loss: 0.1065\n",
      "Epoch [3/10], iteration [311/501] Loss: 0.1055\n",
      "Epoch [3/10], iteration [312/501] Loss: 0.1193\n",
      "Epoch [3/10], iteration [313/501] Loss: 0.0683\n",
      "Epoch [3/10], iteration [314/501] Loss: 0.0764\n",
      "Epoch [3/10], iteration [315/501] Loss: 0.0777\n",
      "Epoch [3/10], iteration [316/501] Loss: 0.0992\n",
      "Epoch [3/10], iteration [317/501] Loss: 0.0569\n",
      "Epoch [3/10], iteration [318/501] Loss: 0.0958\n",
      "Epoch [3/10], iteration [319/501] Loss: 0.1163\n",
      "Epoch [3/10], iteration [320/501] Loss: 0.0861\n",
      "Epoch [3/10], iteration [321/501] Loss: 0.0827\n",
      "Epoch [3/10], iteration [322/501] Loss: 0.0976\n",
      "Epoch [3/10], iteration [323/501] Loss: 0.0735\n",
      "Epoch [3/10], iteration [324/501] Loss: 0.0809\n",
      "Epoch [3/10], iteration [325/501] Loss: 0.0821\n",
      "Epoch [3/10], iteration [326/501] Loss: 0.0787\n",
      "Epoch [3/10], iteration [327/501] Loss: 0.0879\n",
      "Epoch [3/10], iteration [328/501] Loss: 0.1319\n",
      "Epoch [3/10], iteration [329/501] Loss: 0.1116\n",
      "Epoch [3/10], iteration [330/501] Loss: 0.0562\n",
      "Epoch [3/10], iteration [331/501] Loss: 0.1209\n",
      "Epoch [3/10], iteration [332/501] Loss: 0.1009\n",
      "Epoch [3/10], iteration [333/501] Loss: 0.0880\n",
      "Epoch [3/10], iteration [334/501] Loss: 0.0906\n",
      "Epoch [3/10], iteration [335/501] Loss: 0.1010\n",
      "Epoch [3/10], iteration [336/501] Loss: 0.1399\n",
      "Epoch [3/10], iteration [337/501] Loss: 0.0999\n",
      "Epoch [3/10], iteration [338/501] Loss: 0.1132\n",
      "Epoch [3/10], iteration [339/501] Loss: 0.1470\n",
      "Epoch [3/10], iteration [340/501] Loss: 0.1371\n",
      "Epoch [3/10], iteration [341/501] Loss: 0.0578\n",
      "Epoch [3/10], iteration [342/501] Loss: 0.0735\n",
      "Epoch [3/10], iteration [343/501] Loss: 0.1049\n",
      "Epoch [3/10], iteration [344/501] Loss: 0.1335\n",
      "Epoch [3/10], iteration [345/501] Loss: 0.1157\n",
      "Epoch [3/10], iteration [346/501] Loss: 0.0970\n",
      "Epoch [3/10], iteration [347/501] Loss: 0.0963\n",
      "Epoch [3/10], iteration [348/501] Loss: 0.1201\n",
      "Epoch [3/10], iteration [349/501] Loss: 0.1203\n",
      "Epoch [3/10], iteration [350/501] Loss: 0.0850\n",
      "Epoch [3/10], iteration [351/501] Loss: 0.1175\n",
      "Epoch [3/10], iteration [352/501] Loss: 0.0733\n",
      "Epoch [3/10], iteration [353/501] Loss: 0.0876\n",
      "Epoch [3/10], iteration [354/501] Loss: 0.0856\n",
      "Epoch [3/10], iteration [355/501] Loss: 0.0799\n",
      "Epoch [3/10], iteration [356/501] Loss: 0.0756\n",
      "Epoch [3/10], iteration [357/501] Loss: 0.1304\n",
      "Epoch [3/10], iteration [358/501] Loss: 0.1086\n",
      "Epoch [3/10], iteration [359/501] Loss: 0.0580\n",
      "Epoch [3/10], iteration [360/501] Loss: 0.0839\n",
      "Epoch [3/10], iteration [361/501] Loss: 0.0917\n",
      "Epoch [3/10], iteration [362/501] Loss: 0.0900\n",
      "Epoch [3/10], iteration [363/501] Loss: 0.1124\n",
      "Epoch [3/10], iteration [364/501] Loss: 0.0555\n",
      "Epoch [3/10], iteration [365/501] Loss: 0.0707\n",
      "Epoch [3/10], iteration [366/501] Loss: 0.1010\n",
      "Epoch [3/10], iteration [367/501] Loss: 0.0778\n",
      "Epoch [3/10], iteration [368/501] Loss: 0.0573\n",
      "Epoch [3/10], iteration [369/501] Loss: 0.1506\n",
      "Epoch [3/10], iteration [370/501] Loss: 0.0784\n",
      "Epoch [3/10], iteration [371/501] Loss: 0.0648\n",
      "Epoch [3/10], iteration [372/501] Loss: 0.0841\n",
      "Epoch [3/10], iteration [373/501] Loss: 0.0847\n",
      "Epoch [3/10], iteration [374/501] Loss: 0.0727\n",
      "Epoch [3/10], iteration [375/501] Loss: 0.0875\n",
      "Epoch [3/10], iteration [376/501] Loss: 0.0891\n",
      "Epoch [3/10], iteration [377/501] Loss: 0.0597\n",
      "Epoch [3/10], iteration [378/501] Loss: 0.0979\n",
      "Epoch [3/10], iteration [379/501] Loss: 0.0747\n",
      "Epoch [3/10], iteration [380/501] Loss: 0.1452\n",
      "Epoch [3/10], iteration [381/501] Loss: 0.0925\n",
      "Epoch [3/10], iteration [382/501] Loss: 0.0735\n",
      "Epoch [3/10], iteration [383/501] Loss: 0.0692\n",
      "Epoch [3/10], iteration [384/501] Loss: 0.0596\n",
      "Epoch [3/10], iteration [385/501] Loss: 0.0777\n",
      "Epoch [3/10], iteration [386/501] Loss: 0.0771\n",
      "Epoch [3/10], iteration [387/501] Loss: 0.1095\n",
      "Epoch [3/10], iteration [388/501] Loss: 0.0936\n",
      "Epoch [3/10], iteration [389/501] Loss: 0.0503\n",
      "Epoch [3/10], iteration [390/501] Loss: 0.0913\n",
      "Epoch [3/10], iteration [391/501] Loss: 0.0803\n",
      "Epoch [3/10], iteration [392/501] Loss: 0.0784\n",
      "Epoch [3/10], iteration [393/501] Loss: 0.1044\n",
      "Epoch [3/10], iteration [394/501] Loss: 0.0899\n",
      "Epoch [3/10], iteration [395/501] Loss: 0.0896\n",
      "Epoch [3/10], iteration [396/501] Loss: 0.1242\n",
      "Epoch [3/10], iteration [397/501] Loss: 0.1006\n",
      "Epoch [3/10], iteration [398/501] Loss: 0.0837\n",
      "Epoch [3/10], iteration [399/501] Loss: 0.1075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], iteration [400/501] Loss: 0.0799\n",
      "Epoch [3/10], iteration [401/501] Loss: 0.1301\n",
      "Epoch [3/10], iteration [402/501] Loss: 0.0976\n",
      "Epoch [3/10], iteration [403/501] Loss: 0.1285\n",
      "Epoch [3/10], iteration [404/501] Loss: 0.0925\n",
      "Epoch [3/10], iteration [405/501] Loss: 0.0977\n",
      "Epoch [3/10], iteration [406/501] Loss: 0.0812\n",
      "Epoch [3/10], iteration [407/501] Loss: 0.1274\n",
      "Epoch [3/10], iteration [408/501] Loss: 0.1180\n",
      "Epoch [3/10], iteration [409/501] Loss: 0.0764\n",
      "Epoch [3/10], iteration [410/501] Loss: 0.1381\n",
      "Epoch [3/10], iteration [411/501] Loss: 0.1051\n",
      "Epoch [3/10], iteration [412/501] Loss: 0.1685\n",
      "Epoch [3/10], iteration [413/501] Loss: 0.1152\n",
      "Epoch [3/10], iteration [414/501] Loss: 0.1359\n",
      "Epoch [3/10], iteration [415/501] Loss: 0.0917\n",
      "Epoch [3/10], iteration [416/501] Loss: 0.0709\n",
      "Epoch [3/10], iteration [417/501] Loss: 0.1141\n",
      "Epoch [3/10], iteration [418/501] Loss: 0.1529\n",
      "Epoch [3/10], iteration [419/501] Loss: 0.1050\n",
      "Epoch [3/10], iteration [420/501] Loss: 0.0907\n",
      "Epoch [3/10], iteration [421/501] Loss: 0.0777\n",
      "Epoch [3/10], iteration [422/501] Loss: 0.1295\n",
      "Epoch [3/10], iteration [423/501] Loss: 0.0794\n",
      "Epoch [3/10], iteration [424/501] Loss: 0.1056\n",
      "Epoch [3/10], iteration [425/501] Loss: 0.1073\n",
      "Epoch [3/10], iteration [426/501] Loss: 0.1148\n",
      "Epoch [3/10], iteration [427/501] Loss: 0.1362\n",
      "Epoch [3/10], iteration [428/501] Loss: 0.0969\n",
      "Epoch [3/10], iteration [429/501] Loss: 0.0900\n",
      "Epoch [3/10], iteration [430/501] Loss: 0.0833\n",
      "Epoch [3/10], iteration [431/501] Loss: 0.0943\n",
      "Epoch [3/10], iteration [432/501] Loss: 0.1369\n",
      "Epoch [3/10], iteration [433/501] Loss: 0.0815\n",
      "Epoch [3/10], iteration [434/501] Loss: 0.1369\n",
      "Epoch [3/10], iteration [435/501] Loss: 0.1008\n",
      "Epoch [3/10], iteration [436/501] Loss: 0.0834\n",
      "Epoch [3/10], iteration [437/501] Loss: 0.0944\n",
      "Epoch [3/10], iteration [438/501] Loss: 0.1115\n",
      "Epoch [3/10], iteration [439/501] Loss: 0.1004\n",
      "Epoch [3/10], iteration [440/501] Loss: 0.0899\n",
      "Epoch [3/10], iteration [441/501] Loss: 0.1356\n",
      "Epoch [3/10], iteration [442/501] Loss: 0.0704\n",
      "Epoch [3/10], iteration [443/501] Loss: 0.0869\n",
      "Epoch [3/10], iteration [444/501] Loss: 0.1111\n",
      "Epoch [3/10], iteration [445/501] Loss: 0.1177\n",
      "Epoch [3/10], iteration [446/501] Loss: 0.1057\n",
      "Epoch [3/10], iteration [447/501] Loss: 0.1179\n",
      "Epoch [3/10], iteration [448/501] Loss: 0.0727\n",
      "Epoch [3/10], iteration [449/501] Loss: 0.0861\n",
      "Epoch [3/10], iteration [450/501] Loss: 0.0693\n",
      "Epoch [3/10], iteration [451/501] Loss: 0.0725\n",
      "Epoch [3/10], iteration [452/501] Loss: 0.0929\n",
      "Epoch [3/10], iteration [453/501] Loss: 0.1141\n",
      "Epoch [3/10], iteration [454/501] Loss: 0.1393\n",
      "Epoch [3/10], iteration [455/501] Loss: 0.1232\n",
      "Epoch [3/10], iteration [456/501] Loss: 0.0797\n",
      "Epoch [3/10], iteration [457/501] Loss: 0.1039\n",
      "Epoch [3/10], iteration [458/501] Loss: 0.0878\n",
      "Epoch [3/10], iteration [459/501] Loss: 0.1130\n",
      "Epoch [3/10], iteration [460/501] Loss: 0.1050\n",
      "Epoch [3/10], iteration [461/501] Loss: 0.0849\n",
      "Epoch [3/10], iteration [462/501] Loss: 0.1009\n",
      "Epoch [3/10], iteration [463/501] Loss: 0.0846\n",
      "Epoch [3/10], iteration [464/501] Loss: 0.0676\n",
      "Epoch [3/10], iteration [465/501] Loss: 0.0847\n",
      "Epoch [3/10], iteration [466/501] Loss: 0.1120\n",
      "Epoch [3/10], iteration [467/501] Loss: 0.0879\n",
      "Epoch [3/10], iteration [468/501] Loss: 0.1212\n",
      "Epoch [3/10], iteration [469/501] Loss: 0.0847\n",
      "Epoch [3/10], iteration [470/501] Loss: 0.0876\n",
      "Epoch [3/10], iteration [471/501] Loss: 0.0930\n",
      "Epoch [3/10], iteration [472/501] Loss: 0.0731\n",
      "Epoch [3/10], iteration [473/501] Loss: 0.0692\n",
      "Epoch [3/10], iteration [474/501] Loss: 0.1078\n",
      "Epoch [3/10], iteration [475/501] Loss: 0.0945\n",
      "Epoch [3/10], iteration [476/501] Loss: 0.0665\n",
      "Epoch [3/10], iteration [477/501] Loss: 0.0820\n",
      "Epoch [3/10], iteration [478/501] Loss: 0.0828\n",
      "Epoch [3/10], iteration [479/501] Loss: 0.0966\n",
      "Epoch [3/10], iteration [480/501] Loss: 0.0902\n",
      "Epoch [3/10], iteration [481/501] Loss: 0.0772\n",
      "Epoch [3/10], iteration [482/501] Loss: 0.1001\n",
      "Epoch [3/10], iteration [483/501] Loss: 0.0928\n",
      "Epoch [3/10], iteration [484/501] Loss: 0.0586\n",
      "Epoch [3/10], iteration [485/501] Loss: 0.1057\n",
      "Epoch [3/10], iteration [486/501] Loss: 0.0615\n",
      "Epoch [3/10], iteration [487/501] Loss: 0.0925\n",
      "Epoch [3/10], iteration [488/501] Loss: 0.1166\n",
      "Epoch [3/10], iteration [489/501] Loss: 0.0881\n",
      "Epoch [3/10], iteration [490/501] Loss: 0.1074\n",
      "Epoch [3/10], iteration [491/501] Loss: 0.1018\n",
      "Epoch [3/10], iteration [492/501] Loss: 0.0526\n",
      "Epoch [3/10], iteration [493/501] Loss: 0.0785\n",
      "Epoch [3/10], iteration [494/501] Loss: 0.0884\n",
      "Epoch [3/10], iteration [495/501] Loss: 0.0600\n",
      "Epoch [3/10], iteration [496/501] Loss: 0.0856\n",
      "Epoch [3/10], iteration [497/501] Loss: 0.0755\n",
      "Epoch [3/10], iteration [498/501] Loss: 0.0938\n",
      "Epoch [3/10], iteration [499/501] Loss: 0.1158\n",
      "Epoch [3/10], iteration [500/501] Loss: 0.0966\n",
      "Epoch [3/10], iteration [501/501] Loss: 0.0578\n",
      "Epoch [3/10], Test Accuracy of the model on the 2350 test images: 98.38297872340425 %\n",
      "Epoch [4/10], iteration [1/501] Loss: 0.0736\n",
      "Epoch [4/10], iteration [2/501] Loss: 0.1460\n",
      "Epoch [4/10], iteration [3/501] Loss: 0.1092\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mNET.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(out,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_iteration_per_epoch = int(np.ceil(len(train)/batch_size))\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    model.train()\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch [{}/{}], iteration [{}/{}] Loss: {:.4f}'.format(epoch, total_epoch, iteration+1, total_iteration_per_epoch, loss.item()))\n",
    "    torch.save(model.state_dict(), 'model_' + str(epoch) + \".pth\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for input, target in test_loader:\n",
    "            images = input.to(device)\n",
    "            labels = target.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Epoch [{}/{}], Test Accuracy of the model on the {} test images: {} %'.format(epoch, total_epoch, total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37463e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5214e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2b128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
